import torch
import torch.nn as nn
from tqdm import tqdm
import os

class Trainer:
    def __init__(self, model, train_loader, val_loader, config, device):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.config = config
        self.device = device
        
        self.optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=self.config['training']['learning_rate']
        )
        self.criterion = nn.BCELoss() # äºŒå…ƒäº¤å‰ç†µæŸå¤±
        self.epochs = self.config['training']['epochs']
        self.checkpoint_dir = self.config['training']['checkpoint_dir']
        
        # TBPTT parameters
        self.chunk_size = config['training']['chunk_size']
        print(f"Trainer initialized with TBPTT chunk_size: {self.chunk_size}")
        
        os.makedirs(self.checkpoint_dir, exist_ok=True)

    def train_one_epoch(self):
        self.model.train()
        total_loss = 0
        total_chunks_processed = 0

        # å¤–å¾ªç¯ï¼šéå†æ‰€æœ‰é•¿åºåˆ— (æ¯ä¸ªepochè¿›è¡ŒNæ¬¡)
        for long_features, long_labels in tqdm(self.train_loader, desc="Epoch Progress"):
            
            # DataLoaderè¿”å›(1, L, D)ï¼Œéœ€è¦è§£åŒ…
            long_features = long_features.squeeze(0).to(self.device)
            long_labels = long_labels.squeeze(0).to(self.device)

            # å†…å¾ªç¯ï¼šåœ¨å½“å‰é•¿åºåˆ—ä¸Šï¼Œä»¥ä¸é‡å çš„æ–¹å¼è¿›è¡Œåˆ‡å—
            for i in range(0, long_features.shape[0], self.chunk_size):
                
                # 1. åˆ‡åˆ†å‡ºå›ºå®šé•¿åº¦çš„å—
                chunk_features = long_features[i : i + self.chunk_size]
                chunk_labels = long_labels[i : i + self.chunk_size]

                # 2. å¦‚æœæ˜¯æœ€åä¸€ä¸ªä¸å®Œæ•´çš„å—ï¼Œåˆ™è·³è¿‡
                if chunk_features.shape[0] != self.chunk_size:
                    continue

                # 3. å‡†å¤‡æ¨¡å‹è¾“å…¥ (å¢åŠ batchç»´åº¦)
                # [chunk_size, dim] -> [1, chunk_size, dim]
                chunk_features = chunk_features.unsqueeze(0)
                
                # 4. æ¸…ç©ºæ¢¯åº¦
                self.optimizer.zero_grad()
                
                # 5. æ¨¡å‹å‰å‘ä¼ æ’­ (çŠ¶æ€åœ¨modelå†…éƒ¨è‡ªåŠ¨é‡ç½®å’Œæ¼”åŒ–)
                predictions = self.model(chunk_features)

                # 6. è®¡ç®—æŸå¤±
                labels_float = chunk_labels.float().unsqueeze(0).unsqueeze(-1)
                loss = self.criterion(predictions, labels_float)
                
                # 7. åå‘ä¼ æ’­ (æ¢¯åº¦è¢«æˆªæ–­åœ¨chunk_sizeé•¿åº¦å†…)
                loss.backward()
                
                # 8. æ›´æ–°æƒé‡
                self.optimizer.step()

                total_loss += loss.item()
                total_chunks_processed += 1
        
        return total_loss / total_chunks_processed if total_chunks_processed > 0 else 0
    
    # ... (validate_one_epoch å’Œ train æ–¹æ³•ä¹ŸåŒæ ·ç®€åŒ–)
    def validate_one_epoch(self):
        self.model.eval()
        total_loss = 0
        total_chunks_processed = 0
        
        with torch.no_grad():
            # å¤–å¾ªç¯ï¼šéå†æ‰€æœ‰é•¿åºåˆ—
            for long_features, long_labels in tqdm(self.val_loader, desc="Validating"):
                
                # DataLoaderè¿”å›(1, L, D)ï¼Œéœ€è¦è§£åŒ…
                long_features = long_features.squeeze(0).to(self.device)
                long_labels = long_labels.squeeze(0).to(self.device)

                # å†…å¾ªç¯ï¼šåœ¨å½“å‰é•¿åºåˆ—ä¸Šè¿›è¡Œåˆ‡å—éªŒè¯
                for i in range(0, long_features.shape[0], self.chunk_size):
                    
                    # 1. åˆ‡åˆ†å‡ºå›ºå®šé•¿åº¦çš„å—
                    chunk_features = long_features[i : i + self.chunk_size]
                    chunk_labels = long_labels[i : i + self.chunk_size]

                    # 2. å¦‚æœæ˜¯æœ€åä¸€ä¸ªä¸å®Œæ•´çš„å—ï¼Œåˆ™è·³è¿‡
                    if chunk_features.shape[0] != self.chunk_size:
                        continue

                    # 3. å‡†å¤‡æ¨¡å‹è¾“å…¥
                    chunk_features = chunk_features.unsqueeze(0)
                    
                    # 4. æ¨¡å‹å‰å‘ä¼ æ’­
                    predictions = self.model(chunk_features)

                    # 5. è®¡ç®—æŸå¤±
                    labels_float = chunk_labels.float().unsqueeze(0).unsqueeze(-1)
                    loss = self.criterion(predictions, labels_float)
                    
                    total_loss += loss.item()
                    total_chunks_processed += 1
                    
        return total_loss / total_chunks_processed if total_chunks_processed > 0 else 0

    def train(self):
        print("ğŸ” DEBUG: Trainer.train() method started")
        best_val_loss = float('inf')
        
        for epoch in range(self.epochs):
            print(f"ğŸ” DEBUG: Starting epoch {epoch + 1}/{self.epochs}")
            train_loss = self.train_one_epoch()
            val_loss = self.validate_one_epoch()
            
            print(f"Epoch {epoch+1}/{self.epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")
            
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                save_path = os.path.join(self.checkpoint_dir, 'best_model.pth')
                torch.save(self.model.state_dict(), save_path)
                print(f"Model saved to {save_path}")