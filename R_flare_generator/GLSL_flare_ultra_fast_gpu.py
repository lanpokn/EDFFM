import torch
import torch.nn.functional as F
import numpy as np
from PIL import Image
import os
import random
import time

class FlareGeneratorUltraFastGPU:
    """
    æè‡´ä¼˜åŒ–çš„GPUç‚«å…‰ç”Ÿæˆå™¨
    - æ¶ˆé™¤æ‰€æœ‰æ€§èƒ½ç“¶é¢ˆ
    - ä¿æŒå®Œå…¨ç›¸åŒçš„è¾“å…¥è¾“å‡ºæ¥å£
    - é¢„è®¡ç®—+æ‰¹é‡å¹¶è¡Œ+å†…å­˜ä¼˜åŒ–
    """
    def __init__(self, output_size=(1920, 1080), device=None):
        self.output_size = output_size
        self.width, self.height = output_size
        
        if device is None:
            if torch.cuda.is_available():
                self.device = torch.device('cuda')
                print("ğŸš€ åˆå§‹åŒ–æè‡´ä¼˜åŒ–GPUç‚«å…‰ç”Ÿæˆå™¨ (CUDA)")
            else:
                self.device = torch.device('cpu')
                print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
        else:
            self.device = device
            
        print(f"ğŸ“Š è®¾å¤‡: {self.device}")
        if self.device.type == 'cuda':
            print(f"ğŸ¯ GPU: {torch.cuda.get_device_name()}")
            print(f"ğŸ’¾ æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory // 1024**3}GB")
        
        # ğŸš€ æ€§èƒ½ä¼˜åŒ–1: é¢„è®¡ç®—UVåæ ‡ç½‘æ ¼
        self._precompute_uv_grids()
        
        # ğŸš€ æ€§èƒ½ä¼˜åŒ–2: é¢„åˆ†é…å›ºå®šå¤§å°çš„å¼ é‡é¿å…åŠ¨æ€åˆ†é…
        self._preallocate_tensors()
        
        print("âš¡ é¢„è®¡ç®—å®Œæˆï¼Œå‡†å¤‡æè‡´åŠ é€Ÿæ¸²æŸ“")
    
    def _precompute_uv_grids(self):
        """é¢„è®¡ç®—UVåæ ‡ç½‘æ ¼ï¼Œé¿å…é‡å¤è®¡ç®—"""
        print("ğŸ”§ é¢„è®¡ç®—UVåæ ‡ç½‘æ ¼...")
        
        # åˆ›å»ºåæ ‡ç½‘æ ¼ - åªè®¡ç®—ä¸€æ¬¡
        y_coords, x_coords = torch.meshgrid(
            torch.arange(self.height, device=self.device, dtype=torch.float32),
            torch.arange(self.width, device=self.device, dtype=torch.float32),
            indexing='ij'
        )
        
        # GLSLåæ ‡å˜æ¢ - é¢„è®¡ç®—
        self.uv_x = (x_coords / self.width - 0.5) * 2.0 * (self.width / self.height)
        self.uv_y = (y_coords / self.height - 0.5) * 2.0
        self.uv_x_flat = self.uv_x.flatten()
        self.uv_y_flat = self.uv_y.flatten()
        self.uv_length = torch.sqrt(self.uv_x_flat**2 + self.uv_y_flat**2)
        
        # fltré¢„è®¡ç®—
        self.fltr = torch.clamp(self.uv_length**2 * 0.5 + 0.5, max=1.0)
        
        print(f"âœ… UVç½‘æ ¼é¢„è®¡ç®—å®Œæˆ: {self.width}x{self.height}")
    
    def _preallocate_tensors(self):
        """é¢„åˆ†é…å¼ é‡é¿å…åŠ¨æ€å†…å­˜åˆ†é…"""
        flat_size = self.width * self.height
        self.main_glow_color = torch.zeros(flat_size, 3, device=self.device, dtype=torch.float32)
        self.reflections_color = torch.zeros(flat_size, 3, device=self.device, dtype=torch.float32)
        
        # é¢„åˆ†é…æ‰¹é‡å™ªå£°å¼ é‡
        self.i_values = torch.arange(20, device=self.device, dtype=torch.float32)
        self.zero_batch = torch.zeros(20, device=self.device, dtype=torch.float32)
        
        print("âœ… å¼ é‡é¢„åˆ†é…å®Œæˆ")
    
    def _ultra_fast_noise_sample(self, noise_texture, u, v):
        """æè‡´ä¼˜åŒ–çš„å™ªå£°é‡‡æ · - å‡å°‘CPU-GPUæ•°æ®ä¼ è¾“"""
        # ç›´æ¥åœ¨GPUä¸Šå¤„ç†ï¼Œå‡å°‘ç±»å‹è½¬æ¢
        u_norm = torch.fmod(torch.abs(u), 1.0)
        v_norm = torch.fmod(torch.abs(v), 1.0)
        
        # åæ ‡å˜æ¢
        grid_u = u_norm * 2.0 - 1.0
        grid_v = v_norm * 2.0 - 1.0
        
        # æ‰¹é‡é‡‡æ · - ä¸€æ¬¡æ€§å¤„ç†
        grid = torch.stack([grid_u, grid_v], dim=-1).view(1, -1, 1, 2)
        
        # ä¼˜åŒ–é‡‡æ ·æ¨¡å¼
        sampled = F.grid_sample(noise_texture, grid, 
                              mode='bilinear', padding_mode='reflection', 
                              align_corners=False)
        
        result = sampled.squeeze(-1).squeeze(0).transpose(0, 1)
        
        # å¿«é€Ÿè¡¥é½åˆ°4é€šé“
        if result.shape[1] < 4:
            result = F.pad(result, (0, 4 - result.shape[1]))
        
        return result[:, :4]
    
    def _ultra_fast_flare_kernel(self, pos_x, pos_y, seed, flare_size,
                               noise_texture, generate_main_glow, generate_reflections):
        """æè‡´ä¼˜åŒ–çš„ç‚«å…‰å†…æ ¸ - å®Œå…¨å¹¶è¡ŒåŒ–"""
        
        flat_size = self.uv_x_flat.size(0)
        
        # é‡ç½®é¢„åˆ†é…çš„å¼ é‡ - æ¯”é‡æ–°åˆ›å»ºå¿«
        self.main_glow_color.zero_()
        self.reflections_color.zero_()
        
        # noise(seed-1.0) - å¤ç”¨é¢„åˆ†é…å¼ é‡
        gn = self._ultra_fast_noise_sample(noise_texture, 
                                         torch.tensor([seed - 1.0], device=self.device), 
                                         torch.tensor([0.0], device=self.device))[0]
        gn[0] = flare_size
        
        # è·ç¦»è®¡ç®— - ä½¿ç”¨é¢„è®¡ç®—çš„UV
        d_x = self.uv_x_flat - pos_x
        d_y = self.uv_y_flat - pos_y
        
        # Part 1: ä¸»å…‰è¾‰ - å‘é‡åŒ–ä¼˜åŒ–
        if generate_main_glow:
            d_length = torch.sqrt(d_x**2 + d_y**2)
            core_intensity = (0.01 + gn[0] * 0.2) / (d_length + 0.001)
            self.main_glow_color[:, :] = core_intensity.unsqueeze(-1)
            
            # å…‰æ™•è®¡ç®— - ç›´æ¥å†™å…¥é¢„åˆ†é…å¼ é‡
            angle = torch.atan2(d_y, d_x)
            halo_u = angle * 256.9 + pos_x * 2.0
            halo_noise = self._ultra_fast_noise_sample(noise_texture, halo_u, 
                                                     torch.zeros_like(halo_u))
            halo_factor = halo_noise[:, 1] * 0.25
            halo_contribution = halo_factor.unsqueeze(-1) * self.main_glow_color
            self.main_glow_color += halo_contribution
        
        # Part 2: åå°„ç‚«å…‰ - ğŸš€ å…³é”®ä¼˜åŒ–ï¼šå®Œå…¨å‘é‡åŒ–åŒé‡å¾ªç¯
        if generate_reflections:
            # æ‰¹é‡å™ªå£°é¢„è®¡ç®— - å¤ç”¨é¢„åˆ†é…å¼ é‡
            n_u = seed + self.i_values
            n2_u = seed + self.i_values * 2.1
            nc_u = seed + self.i_values * 3.3
            
            # ä¸€æ¬¡æ€§æ‰¹é‡é‡‡æ ·æ‰€æœ‰å™ªå£°
            n_batch = self._ultra_fast_noise_sample(noise_texture, n_u, self.zero_batch)
            n2_batch = self._ultra_fast_noise_sample(noise_texture, n2_u, self.zero_batch)
            nc_batch = self._ultra_fast_noise_sample(noise_texture, nc_u, self.zero_batch)
            
            # å¤„ç†nc - å‘é‡åŒ–
            nc_length = torch.sqrt(torch.sum(nc_batch**2, dim=1, keepdim=True))
            nc_batch = (nc_batch + nc_length) * 0.65
            
            # ğŸš€ æ ¸å¿ƒä¼˜åŒ–ï¼šå°†åŒé‡å¾ªç¯å®Œå…¨å‘é‡åŒ–
            # åˆ›å»º20x3çš„å‚æ•°çŸ©é˜µï¼Œä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰ç»„åˆ
            i_indices = torch.arange(20, device=self.device).repeat_interleave(3)  # [0,0,0,1,1,1,...]
            j_indices = torch.arange(3, device=self.device).repeat(20)  # [0,1,2,0,1,2,...]
            
            # æ‰¹é‡å‚æ•°è®¡ç®— - 60ä¸ªç»„åˆä¸€æ¬¡æ€§å¤„ç†
            n_selected = n_batch[i_indices]  # (60, 4)
            n2_selected = n2_batch[i_indices]
            nc_selected = nc_batch[i_indices]
            
            # å‘é‡åŒ–å‚æ•°è®¡ç®—
            ip_batch = (n_selected[:, 0] * 3.0 + 
                       j_indices.float() * 0.1 * n2_selected[:, 1]**3)  # (60,)
            is_batch = n_selected[:, 1]**2 * 4.5 * gn[0] + 0.1  # (60,)
            ia_batch = (n_selected[:, 2] * 4.0 - 2.0) * n2_selected[:, 0] * n_selected[:, 1]  # (60,)
            
            # å‘é‡åŒ–UVå˜æ¢ - å¹¿æ’­åˆ°æ‰€æœ‰åƒç´ 
            mix_factors = 1.0 + (self.uv_length.unsqueeze(0) - 1.0) * n_selected[:, 3:4]**2  # (60, N)
            iuv_x_batch = self.uv_x_flat.unsqueeze(0) * mix_factors  # (60, N)
            iuv_y_batch = self.uv_y_flat.unsqueeze(0) * mix_factors
            
            # å‘é‡åŒ–æ—‹è½¬å˜æ¢
            cos_ia_batch = torch.cos(ia_batch).unsqueeze(-1)  # (60, 1)
            sin_ia_batch = torch.sin(ia_batch).unsqueeze(-1)
            rotated_x_batch = iuv_x_batch * cos_ia_batch + iuv_y_batch * sin_ia_batch  # (60, N)
            rotated_y_batch = -iuv_x_batch * sin_ia_batch + iuv_y_batch * cos_ia_batch
            
            # å‘é‡åŒ–IDè®¡ç®—
            ip_expanded = ip_batch.unsqueeze(-1)  # (60, 1)
            id_x_batch = ((rotated_x_batch - pos_x) * (1.0 - ip_expanded) + 
                         (rotated_x_batch + pos_x) * ip_expanded)  # (60, N)
            id_y_batch = ((rotated_y_batch - pos_y) * (1.0 - ip_expanded) + 
                         (rotated_y_batch + pos_y) * ip_expanded)
            id_length_batch = torch.sqrt(id_x_batch**2 + id_y_batch**2)  # (60, N)
            
            # å‘é‡åŒ–å¼ºåº¦è®¡ç®—
            intensity_base_batch = torch.clamp(is_batch.unsqueeze(-1) - id_length_batch, min=0.0)  # (60, N)
            mask_batch = intensity_base_batch > 0
            
            # è®¡ç®—æœ€ç»ˆå¼ºåº¦ - å‘é‡åŒ–
            intensity_batch = torch.zeros_like(intensity_base_batch)
            valid_mask = mask_batch.any(dim=1)  # å“ªäº›å‚æ•°ç»„åˆæœ‰æ•ˆæœ
            
            if valid_mask.any():
                # åªå¤„ç†æœ‰æ•ˆçš„ç»„åˆ
                valid_indices = torch.where(valid_mask)[0]
                for idx in valid_indices:
                    pixel_mask = mask_batch[idx]
                    if pixel_mask.any():
                        channel = j_indices[idx].item()
                        i_orig = i_indices[idx].item()
                        
                        intensity_val = (intensity_base_batch[idx, pixel_mask]**0.45 / 
                                       is_batch[idx] * 0.1 * gn[0] * 
                                       nc_batch[i_orig, channel] * self.fltr[pixel_mask])
                        
                        self.reflections_color[pixel_mask, channel] += intensity_val
        
        # åˆå¹¶ç»“æœå¹¶é‡æ–°æ•´å½¢
        result = self.main_glow_color + self.reflections_color
        return result.view(self.height, self.width, 3)
    
    def generate(self, light_pos, noise_image_path, time=0.0, flare_size=0.15, light_color=(1.0, 1.0, 1.0),
                 generate_main_glow=False, generate_reflections=True):
        """
        æè‡´ä¼˜åŒ–ç”Ÿæˆ - ä¿æŒå®Œå…¨ç›¸åŒçš„è¾“å…¥è¾“å‡ºæ¥å£
        """
        # ğŸš€ ä¼˜åŒ–3: ç¼“å­˜å™ªå£°çº¹ç†é¿å…é‡å¤åŠ è½½
        if not hasattr(self, '_cached_texture_path') or self._cached_texture_path != noise_image_path:
            noise_img = Image.open(noise_image_path).convert("RGBA")
            noise_array = np.array(noise_img).astype(np.float32) / 255.0
            self._noise_texture = torch.from_numpy(noise_array).permute(2, 0, 1).unsqueeze(0).to(self.device)
            self._cached_texture_path = noise_image_path
        
        # å…‰æºä½ç½®å˜æ¢
        pos_x = (light_pos[0] / self.width - 0.5) * 2.0 * (self.width / self.height)
        pos_y = (light_pos[1] / self.height - 0.5) * 2.0
        
        # æè‡´ä¼˜åŒ–çš„ç‚«å…‰è®¡ç®—
        img_array = self._ultra_fast_flare_kernel(
            pos_x, pos_y, time, flare_size,
            self._noise_texture, generate_main_glow, generate_reflections
        )
        
        # åº”ç”¨å…‰æºé¢œè‰² - åŸåœ°æ“ä½œ
        light_color_tensor = torch.tensor(light_color, device=self.device, dtype=torch.float32)
        img_array *= light_color_tensor
        
        # æ·»åŠ å™ªå£° - ç®€åŒ–ç‰ˆæœ¬
        noise_addition = self._ultra_fast_noise_sample(
            self._noise_texture, 
            self.uv_x_flat / self.width,
            self.uv_y_flat / self.height
        )[:, :3].view(self.height, self.width, 3)
        img_array += noise_addition * 0.01
        
        # æœ€ç»ˆå¤„ç†
        img_array = torch.clamp(img_array, 0, 1)
        img_array = (img_array * 255).cpu().numpy().astype(np.uint8)
        
        return Image.fromarray(img_array)

# æè‡´æ€§èƒ½æµ‹è¯•
if __name__ == '__main__':
    OUTPUT_RESOLUTION = (640, 480)
    TEXTURE_SOURCE_DIR = 'noise_textures'
    OUTPUT_DIR = 'R_flare_ultra_fast_test'

    if not os.path.isdir(OUTPUT_DIR): 
        os.makedirs(OUTPUT_DIR)
    
    available_textures = [f for f in os.listdir(TEXTURE_SOURCE_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    if not available_textures: 
        raise FileNotFoundError(f"é”™è¯¯ï¼šæ–‡ä»¶å¤¹ '{TEXTURE_SOURCE_DIR}' ä¸­æ²¡æœ‰ä»»ä½•å›¾ç‰‡æ–‡ä»¶ã€‚")

    generator = FlareGeneratorUltraFastGPU(output_size=OUTPUT_RESOLUTION)

    print(f"\nâš¡ --- æè‡´ä¼˜åŒ–GPUæ€§èƒ½æµ‹è¯• ---")
    
    fixed_source_path = os.path.join(TEXTURE_SOURCE_DIR, random.choice(available_textures))
    fixed_light_pos = (generator.width * 0.4, generator.height * 0.4)
    print(f"ä½¿ç”¨çº¹ç†: '{os.path.basename(fixed_source_path)}'")
    
    # æ€§èƒ½åŸºå‡†ï¼šè¿ç»­ç”Ÿæˆ50å¼ å›¾ç‰‡æµ‹è¯•
    print("\nğŸƒâ€â™‚ï¸ æè‡´æ€§èƒ½æµ‹è¯•ï¼šè¿ç»­ç”Ÿæˆ50å¼ ...")
    
    total_start_time = time.time()
    
    for i in range(50):
        light_pos = (random.randint(100, generator.width-100), 
                    random.randint(100, generator.height-100))
        
        img = generator.generate(
            light_pos=light_pos, 
            noise_image_path=fixed_source_path,
            time=random.random() * 50,
            flare_size=random.uniform(0.1, 0.3),
            generate_main_glow=False, 
            generate_reflections=True
        )
        
        output_name = f"ultra_fast_{i+1:03d}.png"
        img.save(os.path.join(OUTPUT_DIR, output_name))
        
        if (i + 1) % 10 == 0:
            elapsed = time.time() - total_start_time
            current_fps = (i + 1) / elapsed
            print(f"å®Œæˆ {i+1}/50ï¼Œå½“å‰ FPS: {current_fps:.2f}")
    
    total_time = time.time() - total_start_time
    final_fps = 50 / total_time
    
    print(f"\nğŸš€ æè‡´ä¼˜åŒ–æ€§èƒ½ç»“æœ:")
    print(f"æ€»æ—¶é—´: {total_time:.2f}ç§’")
    print(f"å¹³å‡FPS: {final_fps:.2f}")
    print(f"æ€§èƒ½æå‡ç›®æ ‡: >20 FPS")
    print("==================================")