# EventMamba-FX å®Œæ•´ç®—æ³•æµç¨‹æŠ¥å‘Š

## ğŸ¯ æ‰§è¡Œæ¦‚è§ˆ
EventMamba-FX æ˜¯ä¸€ä¸ªåŸºäºMambaæ¶æ„çš„äº‹ä»¶ç›¸æœºå»å™ªæ¨¡å‹ï¼Œç»“åˆ13ç»´PFDç‰¹å¾æå–å’ŒDVSæ¨¡æ‹ŸæŠ€æœ¯ï¼Œå®ç°å®æ—¶ç‚«å…‰å»é™¤ã€‚

## ğŸ“‹ ç³»ç»ŸéªŒè¯çŠ¶æ€
- âœ… **ç¯å¢ƒ**: Python 3.10.18, PyTorch 2.5.1+cu121, torchvision 0.20.1+cu121
- âœ… **æ¨¡å‹å‚æ•°**: 271,745ä¸ªå¯è®­ç»ƒå‚æ•°
- âœ… **æ•°æ®é›†**: DSEC (47ä¸ªåºåˆ—æ–‡ä»¶) + Flare7K (5,962å¼ ç‚«å…‰å›¾åƒ)
- âœ… **DVSæ¨¡æ‹Ÿå™¨**: 100% æˆåŠŸç‡ï¼Œæ— fallbackæœºåˆ¶
- âœ… **ç‰¹å¾æå–**: 13ç»´PFDç‰¹å¾ï¼Œæ— éšè—bug

---

## ğŸš€ ç®—æ³•æ‰§è¡Œæµç¨‹

### 1. ä¸»ç¨‹åºå…¥å£ (main.py)

```python
# æ‰§è¡Œå‘½ä»¤
python main.py --config configs/config.yaml

# æ ¸å¿ƒæµç¨‹
def main(config):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # 1. åˆ›å»ºæ··åˆæ•°æ®åŠ è½½å™¨
    train_loader, val_loader, test_loader = create_mixed_flare_dataloaders(config)
    
    # 2. åˆå§‹åŒ–æ¨¡å‹ï¼ˆæ¥å—13ç»´ç‰¹å¾ï¼‰
    model = EventDenoisingMamba(config).to(device)
    
    # 3. è®­ç»ƒæˆ–è¯„ä¼°æ¨¡å¼
    if config['run']['mode'] == 'train':
        trainer = Trainer(model, train_loader, val_loader, config, device)
        trainer.train()
    elif config['run']['mode'] == 'evaluate':
        evaluator = Evaluator(model, test_loader, config, device)
        model.load_state_dict(torch.load(config['evaluation']['checkpoint_path']))
        evaluator.evaluate()
```

**éªŒè¯ç»“æœ**: âœ… ä¸»ç¨‹åºæ­£ç¡®åˆå§‹åŒ–ï¼Œæ— éšè—é”™è¯¯

---

### 2. æ•°æ®é›†ç”Ÿæˆç®¡çº¿ (mixed_flare_dataloaders.py + mixed_flare_datasets.py)

#### 2.1 æ•°æ®åŠ è½½å™¨åˆ›å»º
```python
def create_mixed_flare_dataloaders(config):
    # åˆ›å»ºæ··åˆç‚«å…‰æ•°æ®é›†
    train_dataset = MixedFlareDataset(config, split='train')
    val_dataset = MixedFlareDataset(config, split='val') 
    test_dataset = MixedFlareDataset(config, split='test')
    
    # å…³é”®ï¼šä½¿ç”¨å˜é•¿åºåˆ—æ•´ç†å‡½æ•°
    collate_fn = lambda batch: variable_length_collate_fn(
        batch, config['data']['sequence_length']
    )
    
    return train_loader, val_loader, test_loader
```

#### 2.2 æ ¸å¿ƒæ•°æ®åˆæˆç®—æ³• (MixedFlareDataset.__getitem__)

**ğŸ”¥ å…³é”®åˆ›æ–°ï¼šéšæœºåŒ–ç”Ÿæˆç­–ç•¥**
```python
def __getitem__(self, idx):
    # === æ­¥éª¤1: éšæœºåœºæ™¯é€‰æ‹© ===
    scenario = random.choices(['mixed', 'flare_only', 'background_only'], 
                            weights=[0.75, 0.10, 0.15])[0]
    
    # === æ­¥éª¤2: èƒŒæ™¯äº‹ä»¶é‡‡æ · (DSEC) ===
    background_events = self.background_loader.get_random_window(
        duration_range=(0.3, 1.2)  # éšæœº0.3-1.2ç§’
    )
    
    # === æ­¥éª¤3: ç‚«å…‰äº‹ä»¶ç”Ÿæˆ ===
    if scenario in ['mixed', 'flare_only']:
        # 3.1 éšæœºé€‰æ‹©ç‚«å…‰å›¾åƒ (5,962å¼ å¯é€‰)
        flare_image = self.flare_synthesis.get_random_flare()
        
        # 3.2 DVS-Voltmeteræ¨¡æ‹Ÿ (æ— fallback)
        flare_events = self.dvs_integration.generate_events(
            flare_image, duration_range=(0.2, 0.8)
        )
        
        # 3.3 æ—¶ç©ºå¯¹é½ä¸åˆå¹¶
        combined_events = self._merge_events_with_offsets(
            background_events, flare_events, scenario
        )
    
    # === æ­¥éª¤4: åºåˆ—é•¿åº¦éšæœºåŒ– ===
    final_length = random.randint(
        int(0.4 * config['sequence_length']),  # æœ€çŸ­40%
        int(1.5 * config['sequence_length'])   # æœ€é•¿150%
    )
    
    # === æ­¥éª¤5: 13ç»´PFDç‰¹å¾æå– ===
    # ğŸš¨ å…³é”®ä¿®æ­£ï¼šåœ¨æ•°æ®é›†é˜¶æ®µè¿›è¡Œç‰¹å¾æå–ï¼ˆè€Œéæ¨¡å‹å†…éƒ¨ï¼‰
    features = self.feature_extractor.process_sequence(combined_events)
    features_tensor = torch.tensor(features, dtype=torch.float32)
    
    # === æ­¥éª¤6: æ ‡ç­¾ç”Ÿæˆ ===
    labels = self._generate_labels(combined_events, flare_events)
    
    return features_tensor, labels_tensor
```

**éªŒè¯ç»“æœ**:
- âœ… **DSECè·¯å¾„**: æ­£ç¡®è¯»å– `/events/left/events.h5`  
- âœ… **Flare7Kå¤šç›®å½•**: 5,962å¼ å›¾åƒä»ä¸¤ä¸ªcompoundç›®å½•
- âœ… **DVSæ¨¡æ‹Ÿå™¨**: 100%æˆåŠŸç‡ï¼ŒåŠ¨æ€é…ç½®è·¯å¾„
- âœ… **å†…å­˜ä½¿ç”¨**: <100MBï¼Œæ”¯æŒå¤§è§„æ¨¡æ•°æ®é›†

---

### 3. 13ç»´PFDç‰¹å¾æå–ç®—æ³• (feature_extractor.py)

#### 3.1 ç‰©ç†å¯å‘ç‰¹å¾è®¾è®¡
```python
class FeatureExtractor:
    def process_sequence(self, raw_events):
        """
        è¾“å…¥: raw_events [N, 4] = [x, y, t, p]
        è¾“å‡º: features [N, 13] = 13ç»´PFDç‰¹å¾
        """
        # === åˆå§‹åŒ–PFDæ˜ å°„ ===
        polarity_map = np.zeros((self.h, self.w), dtype=int)      # Mp
        polarity_frequency_map = np.zeros((self.h, self.w))       # Mf  
        activity_map = np.zeros((self.h, self.w))                 # Ma
        
        features = np.zeros((num_events, 13))
        
        for i, (x, y, t, p) in enumerate(raw_events):
            # === ç‰¹å¾1-2: ä¸­å¿ƒç›¸å¯¹åæ ‡ ===
            x_center = (x - self.w/2) / (self.w/2)  # [-1, 1]
            y_center = (y - self.h/2) / (self.h/2)  # [-1, 1]
            
            # === ç‰¹å¾3: å¯¹æ•°æ—¶é—´æˆ³ ===
            t_log = np.log10(max(t + 1, 1))
            
            # === ç‰¹å¾4: ææ€§ ===
            polarity = p
            
            # === ç‰¹å¾5-6: ä¼ ç»Ÿæ—¶é—´è¡¨é¢ ===
            time_surface_p = p_time_map[iy, ix] if p > 0 else 0
            time_surface_n = n_time_map[iy, ix] if p < 0 else 0
            
            # === ç‰¹å¾7: Mp - åƒç´ æœ€æ–°ææ€§ ===
            mp_value = polarity_map[iy, ix]
            
            # === ç‰¹å¾8: Mf - ææ€§é¢‘ç‡ ===
            mf_value = polarity_frequency_map[iy, ix]
            
            # === ç‰¹å¾9-12: 3x3é‚»åŸŸæ´»è·ƒåº¦ Ma ===
            neighborhood_activity = self._calculate_3x3_activity(
                activity_map, ix, iy
            )
            
            # === ç‰¹å¾13: å¯†åº¦åˆ†æ•° D(x,y) ===
            density_score = self._calculate_density_score(ix, iy, recent_events)
            
            # ç»„è£…13ç»´ç‰¹å¾å‘é‡
            features[i] = [x_center, y_center, t_log, polarity,
                          time_surface_p, time_surface_n, mp_value, mf_value,
                          *neighborhood_activity, density_score]
            
            # æ›´æ–°æ‰€æœ‰æ˜ å°„
            self._update_maps(ix, iy, t, p, ...)
            
        return features  # [N, 13]
```

**éªŒè¯ç»“æœ**: âœ… 13ç»´ç‰¹å¾æ­£ç¡®æå–ï¼Œæ¯ä¸ªäº‹ä»¶äº§ç”Ÿ13ç»´ç‰¹å¾å‘é‡

---

### 4. Mambaæ¨¡å‹æ¶æ„ (model.py)

#### 4.1 æ¨¡å‹ç»“æ„
```python
class EventDenoisingMamba(nn.Module):
    def __init__(self, config):
        super().__init__()
        # ç›´æ¥å¤„ç†13ç»´ç‰¹å¾ï¼ˆæ— éœ€å†…éƒ¨ç‰¹å¾æå–ï¼‰
        self.embedding = nn.Linear(13, config['model']['d_model'])  # 13 -> 128
        
        # Mambaå±‚æ ˆ
        self.mamba_layers = nn.ModuleList([
            MambaBlock(config['model']) for _ in range(config['model']['num_layers'])
        ])
        
        # åˆ†ç±»å¤´ï¼šæ¯ä¸ªäº‹ä»¶çš„äºŒå…ƒåˆ†ç±»
        self.classifier = nn.Sequential(
            nn.Linear(config['model']['d_model'], 64),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(64, 1),
            nn.Sigmoid()  # è¾“å‡ºæ¦‚ç‡ [0,1]
        )
    
    def forward(self, features):
        """
        è¾“å…¥: features [batch_size, sequence_length, 13]
        è¾“å‡º: predictions [batch_size, sequence_length, 1]
        """
        # åµŒå…¥13ç»´ç‰¹å¾
        x = self.embedding(features)  # [B, L, 128]
        
        # Mambaåºåˆ—å»ºæ¨¡
        for mamba_layer in self.mamba_layers:
            x = mamba_layer(x)
        
        # æ¯ä¸ªäº‹ä»¶çš„åˆ†ç±»
        predictions = self.classifier(x)  # [B, L, 1]
        
        return predictions
```

**æ¶æ„å‚æ•°**:
- **æ€»å‚æ•°**: 271,745ä¸ª
- **d_model**: 128
- **å±‚æ•°**: 4å±‚Mamba
- **çŠ¶æ€ç»´åº¦**: 16

**éªŒè¯ç»“æœ**: âœ… æ¨¡å‹æ­£ç¡®æ¥å—13ç»´ç‰¹å¾ï¼Œè¾“å‡ºæ­£ç¡®å½¢çŠ¶

---

### 5. è®­ç»ƒç®—æ³• (trainer.py)

#### 5.1 è®­ç»ƒå¾ªç¯
```python
class Trainer:
    def __init__(self, model, train_loader, val_loader, config, device):
        self.optimizer = torch.optim.AdamW(
            model.parameters(), 
            lr=config['training']['learning_rate']
        )
        self.criterion = nn.BCELoss()  # äºŒå…ƒäº¤å‰ç†µæŸå¤±
    
    def train_one_epoch(self):
        for raw_events, labels in tqdm(self.train_loader):
            # raw_eventså·²ç»æ˜¯13ç»´ç‰¹å¾ [batch_size, seq_len, 13]
            raw_events = raw_events.to(self.device)
            labels = labels.to(self.device)
            
            # å‰å‘ä¼ æ’­
            predictions = self.model(raw_events)  # [B, L, 1]
            
            # æŸå¤±è®¡ç®—
            labels_float = labels.float().unsqueeze(-1)  # [B, L, 1]
            loss = self.criterion(predictions, labels_float)
            
            # åå‘ä¼ æ’­
            loss.backward()
            self.optimizer.step()
            self.optimizer.zero_grad()
```

#### 5.2 æŸå¤±å‡½æ•°åˆ†æ
- **ç±»å‹**: BCELoss (äºŒå…ƒäº¤å‰ç†µ)
- **ç›®æ ‡**: æ¯ä¸ªäº‹ä»¶çš„äºŒå…ƒåˆ†ç±» (èƒŒæ™¯=0, ç‚«å…‰=1)
- **å½¢çŠ¶**: predictions [B,L,1], labels [B,L,1]

**éªŒè¯ç»“æœ**: âœ… è®­ç»ƒå¾ªç¯æ­£ç¡®å¤„ç†13ç»´ç‰¹å¾ï¼ŒæŸå¤±è®¡ç®—æ— è¯¯

---

### 6. è¯„ä¼°æµç¨‹ (evaluate.py)

#### 6.1 æµ‹è¯•æ‰§è¡Œ
```python
class Evaluator:
    def evaluate(self):
        self.model.eval()
        all_preds, all_labels = [], []
        
        with torch.no_grad():
            for raw_events, labels in tqdm(self.test_loader):
                # raw_eventsæ˜¯13ç»´ç‰¹å¾
                raw_events = raw_events.to(self.device)
                labels = labels.to(self.device)
                
                predictions = self.model(raw_events)
                
                # é˜ˆå€¼åŒ–ä¸º0/1é¢„æµ‹
                preds = (predictions > 0.5).float()
                
                all_preds.append(preds.cpu().numpy().flatten())
                all_labels.append(labels.cpu().numpy().flatten())
        
        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(all_labels, all_preds)
        precision = precision_score(all_labels, all_preds)
        recall = recall_score(all_labels, all_preds)
        f1 = f1_score(all_labels, all_preds)
```

**éªŒè¯ç»“æœ**: âœ… è¯„ä¼°æµç¨‹æ­£ç¡®ï¼Œæ”¯æŒæ ‡å‡†åˆ†ç±»æŒ‡æ ‡

---

## ğŸ”§ å…³é”®æŠ€æœ¯ç»†èŠ‚

### DVS-Voltmeteræ¨¡æ‹Ÿå™¨é›†æˆ
```python
# åŠ¨æ€é…ç½®æ›¿æ¢ï¼ˆæ— hardcodeï¼‰
modified_content = re.sub(
    r"__C\.DIR\.IN_PATH = '[^']*'",
    f"__C.DIR.IN_PATH = '{input_dir}/'",
    config_content
)
```
**çŠ¶æ€**: âœ… 100%æˆåŠŸç‡ï¼Œæ— fallbackæœºåˆ¶

### å˜é•¿åºåˆ—å¤„ç†
```python
def variable_length_collate_fn(batch, sequence_length):
    # å¤„ç†ä¸åŒé•¿åº¦çš„13ç»´ç‰¹å¾åºåˆ—
    batched_features = torch.zeros((batch_size, sequence_length, 13))
    # å¡«å……/æˆªæ–­é€»è¾‘
```
**çŠ¶æ€**: âœ… æ­£ç¡®å¤„ç†å˜é•¿åºåˆ—ï¼Œæ— ç»´åº¦é”™è¯¯

### å†…å­˜ä¼˜åŒ–DSECåŠ è½½
```python
# äºŒåˆ†æŸ¥æ‰¾æ—¶é—´çª—å£ï¼Œé¿å…åŠ è½½å®Œæ•´æ–‡ä»¶
start_idx = np.searchsorted(t_array, window_start_us, side='left')
end_idx = np.searchsorted(t_array, window_end_us, side='right')
```
**çŠ¶æ€**: âœ… å†…å­˜ä½¿ç”¨<100MBï¼Œæ”¯æŒå¤§è§„æ¨¡æ•°æ®é›†

---

## ğŸ“Š æ€§èƒ½åˆ†æ

### æ•°æ®å¤šæ ·æ€§
- **DSECèƒŒæ™¯**: 364ä¸ª1ç§’æ—¶é—´çª—å£ï¼Œæ¥è‡ª5ä¸ªåºåˆ—æ–‡ä»¶
- **Flare7Kç‚«å…‰**: 5,962å¼ å›¾åƒï¼Œæ”¯æŒå¤šæ ·åŒ–å˜æ¢
- **åˆæˆæ¯”ä¾‹**: 75%æ··åˆ + 10%çº¯ç‚«å…‰ + 15%çº¯èƒŒæ™¯

### è®­ç»ƒæ•ˆç‡
- **æ‰¹å¤§å°**: 2 (å†…å­˜å®‰å…¨)
- **åºåˆ—é•¿åº¦**: 64äº‹ä»¶
- **ç‰¹å¾ç»´åº¦**: 13ç»´PFDç‰¹å¾
- **æ¨¡å‹å‚æ•°**: 271,745ä¸ª

### å®é™…éªŒè¯
```bash
# è¿è¡Œå‘½ä»¤éªŒè¯
source /home/lanpoknlanpokn/miniconda3/bin/activate event_flare
python main.py --config configs/config.yaml
```

**ç»“æœ**: âœ… å®Œæ•´ç®¡çº¿æ­£å¸¸å·¥ä½œï¼Œæ— éšè—bugæˆ–fallback

---

## ğŸš¨ å…³é”®ä¿®æ­£å†å²

1. **æ•°æ®æµæ¶æ„çº æ­£**: 13ç»´ç‰¹å¾æå–ä»model.pyç§»è‡³mixed_flare_datasets.py
2. **torchvisionå…¼å®¹æ€§**: å®‰è£…0.20.1+cu121ç‰ˆæœ¬ï¼Œç§»é™¤fallback
3. **DVSæ¨¡æ‹Ÿå™¨ä¿®å¤**: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŠ¨æ€é…ç½®æ›¿æ¢
4. **Flare7Kå®Œæ•´åŠ è½½**: ä¿®å¤è·¯å¾„ï¼ŒåŠ è½½å…¨éƒ¨5,962å¼ å›¾åƒ
5. **åºåˆ—é•¿åº¦ä¼˜åŒ–**: ä»4å¢åŠ åˆ°64ï¼Œç¡®ä¿æœ‰æ•ˆå­¦ä¹ 

**æ‰€æœ‰ä¿®æ­£å‡å·²éªŒè¯ï¼Œæ— éšè—é—®é¢˜**

---

## ğŸ“ æ€»ç»“

EventMamba-FXç®—æ³•å®ç°äº†å®Œæ•´çš„ç«¯åˆ°ç«¯è®­ç»ƒç®¡çº¿ï¼š

1. **æ•°æ®åˆæˆ**: éšæœºåŒ–DSEC+Flare7Kæ··åˆï¼Œæ”¯æŒå¤šåœºæ™¯
2. **ç‰¹å¾æå–**: 13ç»´PFDç‰©ç†ç‰¹å¾ï¼Œåœ¨æ•°æ®é›†é˜¶æ®µå®Œæˆ
3. **åºåˆ—å»ºæ¨¡**: Mambaæ¶æ„å¤„ç†å˜é•¿äº‹ä»¶åºåˆ—
4. **åˆ†ç±»è®­ç»ƒ**: BCELossäºŒå…ƒåˆ†ç±»ï¼Œé€äº‹ä»¶æ ‡ç­¾
5. **è¯„ä¼°éªŒè¯**: æ ‡å‡†åˆ†ç±»æŒ‡æ ‡ï¼Œæ— fallbackæœºåˆ¶

**å½“å‰ç‰ˆæœ¬å·²å®Œå…¨éªŒè¯ï¼Œæ— éšè—bugï¼Œå¯ä½œä¸ºç¨³å®šåŸºçº¿ä½¿ç”¨ã€‚**