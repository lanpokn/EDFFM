#!/usr/bin/env python3
"""
å®Œæ•´æ•°æ®ç®¡çº¿åˆ†æ

åˆ†æå®Œæ•´çš„è®­ç»ƒæ•°æ®ç”Ÿæˆæµç¨‹ï¼š
1. DSECèƒŒæ™¯äº‹ä»¶è¯»å–ä¸åˆ†æ
2. DVSç‚«å…‰äº‹ä»¶ä»¿çœŸä¸åˆ†æ  
3. äº‹ä»¶åˆå¹¶ä¸æœ€ç»ˆåˆ†æ
4. ä¸‰ç»„ä»¶å¯è§†åŒ–å¯¹æ¯”

ç›®æ ‡ï¼šç†è§£æ¯ä¸ªç»„ä»¶çš„è´¡çŒ®å’Œåˆç†æ€§
"""

import sys
import os
import yaml
import traceback
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

# Add src path for imports
src_path = os.path.join(os.path.dirname(__file__), 'src')
if src_path not in sys.path:
    sys.path.append(src_path)

def create_event_visualization(events, title, save_path, resolution=(640, 480)):
    """åˆ›å»ºäº‹ä»¶å¯è§†åŒ–å›¾åƒ."""
    if len(events) == 0:
        print(f"âš ï¸  No events to visualize for {title}")
        return
    
    # Extract coordinates and polarities
    x = events[:, 1].astype(int)
    y = events[:, 2].astype(int) 
    p = events[:, 3].astype(int)
    
    # Filter valid coordinates
    valid = (x >= 0) & (x < resolution[0]) & (y >= 0) & (y < resolution[1])
    x, y, p = x[valid], y[valid], p[valid]
    
    # Create visualization
    fig, ax = plt.subplots(1, 1, figsize=(10, 8))
    
    # Plot positive and negative events
    pos_mask = p > 0
    neg_mask = p <= 0
    
    if np.any(pos_mask):
        ax.scatter(x[pos_mask], y[pos_mask], c='red', s=0.1, alpha=0.6, label=f'ON ({np.sum(pos_mask)})')
    if np.any(neg_mask):
        ax.scatter(x[neg_mask], y[neg_mask], c='blue', s=0.1, alpha=0.6, label=f'OFF ({np.sum(neg_mask)})')
    
    ax.set_xlim(0, resolution[0])
    ax.set_ylim(resolution[1], 0)  # Flip Y axis
    ax.set_xlabel('X (pixels)')
    ax.set_ylabel('Y (pixels)')
    ax.set_title(f'{title}\nTotal Events: {len(events):,}')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"âœ… Saved visualization: {save_path}")

def analyze_dsec_background():
    """åˆ†æDSECèƒŒæ™¯äº‹ä»¶."""
    print("ğŸ“Š Analyzing DSEC Background Events")
    print("=" * 50)
    
    try:
        # Load configuration
        with open("configs/config.yaml", 'r') as f:
            config = yaml.safe_load(f)
        
        # Import DSEC efficient loader
        from dsec_efficient import DSECEfficientDataset
        
        # Create dataset
        dataset = DSECEfficientDataset(
            dsec_path=config['data']['dsec_path'],
            sequence_length=config['data']['sequence_length'],
            time_window_us=config['data']['time_window_us']
        )
        
        print(f"DSEC dataset loaded: {len(dataset)} sequences")
        
        # Sample a few sequences
        background_events_list = []
        for i in range(min(3, len(dataset))):
            try:
                events, _ = dataset[i]  # Get events and metadata
                background_events_list.append(events)
                
                # Calculate time span and density
                if len(events) > 0:
                    time_span_us = events[-1, 0] - events[0, 0]  # First column is timestamp
                    time_span_ms = time_span_us / 1000.0
                    density = len(events) / time_span_ms if time_span_ms > 0 else 0
                    
                    print(f"Sample {i+1}:")
                    print(f"  Events: {len(events):,}")
                    print(f"  Time span: {time_span_ms:.1f}ms")
                    print(f"  Density: {density:.1f} events/ms")
                    print(f"  Spatial range: X({events[:,1].min():.0f}-{events[:,1].max():.0f}), Y({events[:,2].min():.0f}-{events[:,2].max():.0f})")
                    print(f"  Polarity dist: {np.unique(events[:,3], return_counts=True)}")
                    
                    # Create visualization for first sample
                    if i == 0:
                        os.makedirs("output/pipeline_analysis", exist_ok=True)
                        create_event_visualization(
                            events, 
                            "DSEC Background Events",
                            "output/pipeline_analysis/dsec_background_events.png"
                        )
                else:
                    print(f"Sample {i+1}: No events")
                    
            except Exception as e:
                print(f"Error loading DSEC sample {i+1}: {e}")
                continue
        
        # Return first valid sample for merging
        for events in background_events_list:
            if len(events) > 0:
                return events
        
        return None
        
    except Exception as e:
        print(f"âŒ DSEC analysis failed: {e}")
        traceback.print_exc()
        return None

def analyze_dvs_flare():
    """åˆ†æDVSç‚«å…‰äº‹ä»¶."""
    print("\nğŸ”¬ Analyzing DVS Flare Events")
    print("=" * 50)
    
    try:
        # Import the integration module
        from dvs_flare_integration import create_flare_event_generator
        
        # Load configuration
        with open("configs/config.yaml", 'r') as f:
            config = yaml.safe_load(f)
        
        config['data']['event_simulator']['type'] = 'dvs_voltmeter'
        config['debug_mode'] = False
        
        # Create generator
        generator = create_flare_event_generator(config)
        
        # Generate flare events
        flare_events, timing_info = generator.generate_flare_events()
        
        print(f"DVS Flare Events Generated:")
        print(f"  Events: {len(flare_events):,}")
        
        if len(flare_events) > 0:
            duration_sec = timing_info.get('duration_sec', 0.1)
            duration_ms = duration_sec * 1000
            density = len(flare_events) / duration_ms if duration_ms > 0 else 0
            
            print(f"  Duration: {duration_ms:.1f}ms")
            print(f"  Density: {density:.1f} events/ms")
            print(f"  Spatial range: X({flare_events[:,1].min():.0f}-{flare_events[:,1].max():.0f}), Y({flare_events[:,2].min():.0f}-{flare_events[:,2].max():.0f})")
            print(f"  Temporal range: {flare_events[:,0].min():.0f}-{flare_events[:,0].max():.0f} Î¼s")
            print(f"  Polarity dist: {np.unique(flare_events[:,3], return_counts=True)}")
            
            # Create visualization
            os.makedirs("output/pipeline_analysis", exist_ok=True)
            create_event_visualization(
                flare_events,
                "DVS Flare Events", 
                "output/pipeline_analysis/dvs_flare_events.png"
            )
            
            return flare_events
        else:
            print("  âŒ No flare events generated!")
            return None
            
    except Exception as e:
        print(f"âŒ DVS flare analysis failed: {e}")
        traceback.print_exc()
        return None

def merge_and_analyze_events(background_events, flare_events):
    """åˆå¹¶å¹¶åˆ†æå®Œæ•´äº‹ä»¶åºåˆ—."""
    print("\nğŸ”„ Merging and Analyzing Complete Event Sequence")
    print("=" * 60)
    
    if background_events is None or flare_events is None:
        print("âŒ Cannot merge - missing background or flare events")
        return None
    
    try:
        print(f"Before merging:")
        print(f"  Background events: {len(background_events):,}")
        print(f"  Flare events: {len(flare_events):,}")
        
        # Simple merge by timestamp (should use proper alignment in real training)
        merged_events = np.vstack([background_events, flare_events])
        
        # Sort by timestamp
        time_sorted_idx = np.argsort(merged_events[:, 0])
        merged_events = merged_events[time_sorted_idx]
        
        print(f"After merging:")
        print(f"  Total events: {len(merged_events):,}")
        
        # Calculate merged statistics
        if len(merged_events) > 0:
            time_span_us = merged_events[-1, 0] - merged_events[0, 0]
            time_span_ms = time_span_us / 1000.0
            density = len(merged_events) / time_span_ms if time_span_ms > 0 else 0
            
            print(f"  Time span: {time_span_ms:.1f}ms")
            print(f"  Merged density: {density:.1f} events/ms")
            print(f"  Spatial range: X({merged_events[:,1].min():.0f}-{merged_events[:,1].max():.0f}), Y({merged_events[:,2].min():.0f}-{merged_events[:,2].max():.0f})")
            
            # Analyze composition
            bg_count = len(background_events)
            flare_count = len(flare_events)
            bg_ratio = bg_count / len(merged_events) * 100
            flare_ratio = flare_count / len(merged_events) * 100
            
            print(f"  Composition: {bg_ratio:.1f}% background, {flare_ratio:.1f}% flare")
            
            # Create visualization
            create_event_visualization(
                merged_events,
                "Merged Events (Background + Flare)",
                "output/pipeline_analysis/merged_events.png"
            )
            
            return merged_events, {
                'background_count': bg_count,
                'flare_count': flare_count,
                'total_count': len(merged_events),
                'density': density,
                'time_span_ms': time_span_ms
            }
        
    except Exception as e:
        print(f"âŒ Event merging failed: {e}")
        traceback.print_exc()
        return None, None

def create_comparison_summary(background_events, flare_events, merged_info):
    """åˆ›å»ºå¯¹æ¯”åˆ†ææ€»ç»“."""
    print("\nğŸ“ˆ Pipeline Component Analysis Summary")
    print("=" * 70)
    
    # Component densities
    bg_density = len(background_events) / 1000 if background_events is not None else 0  # Approximate
    flare_density = len(flare_events) / 100 if flare_events is not None else 0  # 100ms typical
    merged_density = merged_info['density'] if merged_info else 0
    
    print(f"ğŸ“Š Event Density Comparison:")
    print(f"  DSEC Background:  ~{bg_density:.1f} events/ms")
    print(f"  DVS Flare:        ~{flare_density:.1f} events/ms")  
    print(f"  Merged Total:     {merged_density:.1f} events/ms")
    print()
    
    if merged_info:
        print(f"ğŸ“Š Event Count Breakdown:")
        print(f"  Background: {merged_info['background_count']:,} ({merged_info['background_count']/merged_info['total_count']*100:.1f}%)")
        print(f"  Flare:      {merged_info['flare_count']:,} ({merged_info['flare_count']/merged_info['total_count']*100:.1f}%)")
        print(f"  Total:      {merged_info['total_count']:,}")
        print()
    
    # Assessment
    print(f"âœ… Pipeline Assessment:")
    if merged_density > 10000:
        print(f"  âš ï¸  HIGH: {merged_density:.1f} events/ms - may need optimization")
    elif merged_density < 100:
        print(f"  âš ï¸  LOW: {merged_density:.1f} events/ms - may need more sensitivity")
    else:
        print(f"  âœ… GOOD: {merged_density:.1f} events/ms - reasonable for training")
    
    print(f"\nğŸ’¡ Recommendations:")
    if bg_density > flare_density * 10:
        print(f"  - Flare events are overwhelmed by background ({bg_density/flare_density:.1f}x difference)")
        print(f"  - Consider reducing background time window or increasing flare intensity")
    elif flare_density > bg_density * 10:
        print(f"  - Flare events dominate background ({flare_density/bg_density:.1f}x difference)")
        print(f"  - Consider reducing flare sensitivity or increasing background window")
    else:
        print(f"  - Good balance between background and flare events")
    
    print(f"\nğŸ“ Visualizations saved to: output/pipeline_analysis/")
    print(f"  - dsec_background_events.png")
    print(f"  - dvs_flare_events.png") 
    print(f"  - merged_events.png")

def main():
    """è¿è¡Œå®Œæ•´ç®¡çº¿åˆ†æ."""
    print("EventMamba-FX Complete Pipeline Analysis")
    print("=" * 70)
    print("Analyzing: DSEC Background â†’ DVS Flare â†’ Merged Training Data")
    print("=" * 70)
    
    # Step 1: Analyze DSEC background events
    background_events = analyze_dsec_background()
    
    # Step 2: Analyze DVS flare events
    flare_events = analyze_dvs_flare()
    
    # Step 3: Merge and analyze complete sequence
    merged_events, merged_info = merge_and_analyze_events(background_events, flare_events)
    
    # Step 4: Create comparison summary
    create_comparison_summary(background_events, flare_events, merged_info)
    
    print("\n" + "=" * 70)
    print("COMPLETE PIPELINE ANALYSIS FINISHED")
    print("=" * 70)

if __name__ == "__main__":
    main()