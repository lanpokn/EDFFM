#!/usr/bin/env python3
"""
ä¸ºtraineræ·»åŠ ä¸´æ—¶çš„NaNå®‰å…¨æ£€æŸ¥è¡¥ä¸
å¯ä»¥åœ¨æœåŠ¡å™¨ä¸Šä½¿ç”¨è¿™ä¸ªæ›¿ä»£validate_one_epochå‡½æ•°
"""

import torch
import numpy as np

def safe_validate_one_epoch(trainer):
    """
    å¸¦æœ‰è¯¦ç»†NaNæ£€æŸ¥çš„å®‰å…¨éªŒè¯å‡½æ•°
    ç”¨äºæ›¿ä»£trainer.validate_one_epoch()
    """
    trainer.model.eval()
    total_loss = 0
    total_chunks_processed = 0
    nan_chunks = 0
    inf_chunks = 0
    
    print(f"ğŸ” å¼€å§‹å®‰å…¨éªŒè¯...")
    
    with torch.no_grad():
        for seq_idx, (long_features, long_labels) in enumerate(trainer.val_loader):
            print(f"   åºåˆ— {seq_idx + 1}/{len(trainer.val_loader)}")
            
            # é‡ç½®éšè—çŠ¶æ€
            trainer.model.reset_hidden_state()
            
            # æ•°æ®ç§»åŠ¨
            long_features = long_features.squeeze(0).to(trainer.device)
            long_labels = long_labels.squeeze(0).to(trainer.device)
            
            # æ£€æŸ¥è¾“å…¥æ•°æ®
            if torch.isnan(long_features).any():
                print(f"     âŒ è¾“å…¥featuresæœ‰NaNï¼Œè·³è¿‡åºåˆ—")
                continue
            if torch.isinf(long_features).any():
                print(f"     âŒ è¾“å…¥featuresæœ‰Infï¼Œè·³è¿‡åºåˆ—")
                continue
            if torch.isnan(long_labels).any():
                print(f"     âŒ è¾“å…¥labelsæœ‰NaNï¼Œè·³è¿‡åºåˆ—")
                continue
            if torch.isinf(long_labels).any():
                print(f"     âŒ è¾“å…¥labelsæœ‰Infï¼Œè·³è¿‡åºåˆ—")
                continue
            
            chunk_count = 0
            # åˆ†å—å¤„ç†
            for i in range(0, long_features.shape[0], trainer.chunk_size):
                chunk_features = long_features[i : i + trainer.chunk_size]
                chunk_labels = long_labels[i : i + trainer.chunk_size]
                
                if chunk_features.shape[0] < 1:
                    continue
                
                chunk_count += 1
                chunk_features = chunk_features.unsqueeze(0)
                
                # å‰å‘ä¼ æ’­
                try:
                    predictions = trainer.model(chunk_features)
                    
                    # æ£€æŸ¥é¢„æµ‹ç»“æœ
                    if torch.isnan(predictions).any():
                        print(f"     âŒ Chunk {chunk_count} é¢„æµ‹æœ‰NaN")
                        nan_chunks += 1
                        continue
                    if torch.isinf(predictions).any():
                        print(f"     âŒ Chunk {chunk_count} é¢„æµ‹æœ‰Inf")
                        inf_chunks += 1
                        continue
                    
                    # è®¡ç®—æŸå¤±
                    loss = trainer.criterion(predictions.squeeze(), chunk_labels.float())
                    
                    # æ£€æŸ¥æŸå¤±
                    if torch.isnan(loss):
                        print(f"     âŒ Chunk {chunk_count} æŸå¤±ä¸ºNaN")
                        print(f"       PredictionsèŒƒå›´: [{predictions.min():.6f}, {predictions.max():.6f}]")
                        print(f"       LabelsèŒƒå›´: [{chunk_labels.min():.6f}, {chunk_labels.max():.6f}]")
                        nan_chunks += 1
                        continue
                    if torch.isinf(loss):
                        print(f"     âŒ Chunk {chunk_count} æŸå¤±ä¸ºInf")
                        inf_chunks += 1
                        continue
                    
                    # ç´¯è®¡æŸå¤±ï¼ˆä½¿ç”¨ä¿®æ­£çš„æƒé‡è®¡ç®—ï¼‰
                    sequence_length = chunk_features.shape[1]
                    total_loss += loss.item() * sequence_length
                    total_chunks_processed += sequence_length
                    
                    if chunk_count <= 3:  # æ‰“å°å‰å‡ ä¸ªchunkçš„ä¿¡æ¯
                        print(f"     Chunk {chunk_count}: Loss={loss.item():.6f}, é•¿åº¦={sequence_length}")
                    
                except Exception as e:
                    print(f"     âŒ Chunk {chunk_count} è®¡ç®—å¤±è´¥: {e}")
                    continue
            
            print(f"     åºåˆ—å®Œæˆ: {chunk_count} chunks")
    
    # è®¡ç®—ç»“æœ
    print(f"\nğŸ“Š éªŒè¯ç»Ÿè®¡:")
    print(f"   æ€»äº‹ä»¶æ•°: {total_chunks_processed}")
    print(f"   NaN chunks: {nan_chunks}")
    print(f"   Inf chunks: {inf_chunks}")
    
    if total_chunks_processed > 0:
        avg_loss = total_loss / total_chunks_processed
        print(f"   å¹³å‡æŸå¤±: {avg_loss:.6f}")
        
        # æœ€ç»ˆæ£€æŸ¥
        if np.isnan(avg_loss):
            print(f"   âŒ æœ€ç»ˆå¹³å‡æŸå¤±ä¸ºNaN!")
            return float('nan')
        elif np.isinf(avg_loss):
            print(f"   âŒ æœ€ç»ˆå¹³å‡æŸå¤±ä¸ºInf!")
            return float('inf')
        else:
            print(f"   âœ… éªŒè¯æˆåŠŸ")
            return avg_loss
    else:
        print(f"   âŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•chunk")
        return float('nan')

def patch_trainer_validation():
    """
    åˆ›å»ºä¸€ä¸ªä½¿ç”¨å®‰å…¨éªŒè¯çš„è®­ç»ƒå‡½æ•°è¡¥ä¸
    """
    code = """
# åœ¨ä½ çš„è®­ç»ƒè„šæœ¬ä¸­ä½¿ç”¨è¿™ä¸ªæ›¿ä»£éªŒè¯å‡½æ•°
# ä¾‹å¦‚åœ¨main.pyæˆ–å•ç‹¬çš„è®­ç»ƒè„šæœ¬ä¸­ï¼š

from safe_trainer_patch import safe_validate_one_epoch

# åœ¨è®­ç»ƒå¾ªç¯ä¸­æ›¿æ¢ï¼š
# val_loss = trainer.validate_one_epoch()
# æ”¹ä¸ºï¼š
# val_loss = safe_validate_one_epoch(trainer)

# æˆ–è€…ç›´æ¥æ›¿æ¢trainerçš„æ–¹æ³•ï¼š
# trainer.validate_one_epoch = lambda: safe_validate_one_epoch(trainer)
"""
    print(code)

if __name__ == "__main__":
    patch_trainer_validation()