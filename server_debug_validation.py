#!/usr/bin/env python3
"""
ä¸“é—¨ç”¨äºæœåŠ¡å™¨ç¯å¢ƒè°ƒè¯•validation NaNé—®é¢˜çš„è„šæœ¬
åŒ…å«è¯¦ç»†çš„ç¯å¢ƒæ£€æŸ¥å’Œæ•°æ®å®Œæ•´æ€§éªŒè¯
"""

import yaml
import torch
import torch.nn as nn
import numpy as np
import sys
import os
import h5py
import glob
from torch.utils.data import DataLoader

sys.path.append('src')
from src.unified_dataset import UnifiedSequenceDataset, create_unified_dataloaders
from src.model import EventDenoisingMamba

def check_environment():
    """æ£€æŸ¥æœåŠ¡å™¨ç¯å¢ƒä¿¡æ¯"""
    print("ğŸ” ç¯å¢ƒä¿¡æ¯æ£€æŸ¥:")
    print(f"   Pythonç‰ˆæœ¬: {sys.version}")
    print(f"   PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"   CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"   CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"   GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
            print(f"     å†…å­˜: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f}GB")
    
    print(f"   NumPyç‰ˆæœ¬: {np.__version__}")
    print(f"   å·¥ä½œç›®å½•: {os.getcwd()}")

def check_h5_data_integrity():
    """æ£€æŸ¥H5éªŒè¯æ•°æ®çš„å®Œæ•´æ€§"""
    print("\nğŸ” H5éªŒè¯æ•°æ®å®Œæ•´æ€§æ£€æŸ¥:")
    
    config_path = 'configs/config.yaml'
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    h5_archive_path = config['data_pipeline']['h5_archive_path']
    val_dir = os.path.join(h5_archive_path, 'val')
    
    print(f"   éªŒè¯æ•°æ®ç›®å½•: {val_dir}")
    
    if not os.path.exists(val_dir):
        print(f"   âŒ éªŒè¯æ•°æ®ç›®å½•ä¸å­˜åœ¨: {val_dir}")
        return False
    
    h5_files = glob.glob(os.path.join(val_dir, '*.h5'))
    print(f"   æ‰¾åˆ° {len(h5_files)} ä¸ªH5æ–‡ä»¶")
    
    for i, h5_file in enumerate(h5_files):
        print(f"\n   æ£€æŸ¥æ–‡ä»¶ {i+1}: {os.path.basename(h5_file)}")
        print(f"     æ–‡ä»¶å¤§å°: {os.path.getsize(h5_file) / 1024**2:.1f}MB")
        
        try:
            with h5py.File(h5_file, 'r') as hf:
                features = hf['features']
                labels = hf['labels']
                
                print(f"     Featureså½¢çŠ¶: {features.shape}")
                print(f"     Labelså½¢çŠ¶: {labels.shape}")
                
                # æ£€æŸ¥ä¸€å°éƒ¨åˆ†æ•°æ®çš„å¼‚å¸¸å€¼
                sample_size = min(1000, features.shape[0])
                features_sample = features[:sample_size]
                labels_sample = labels[:sample_size]
                
                # æ£€æŸ¥NaNå’ŒInf
                has_nan_features = np.isnan(features_sample).any()
                has_inf_features = np.isinf(features_sample).any()
                has_nan_labels = np.isnan(labels_sample).any()
                has_inf_labels = np.isinf(labels_sample).any()
                
                if has_nan_features or has_inf_features:
                    print(f"     âŒ Featuresæœ‰å¼‚å¸¸å€¼: NaN={has_nan_features}, Inf={has_inf_features}")
                    
                    # è¯¦ç»†åˆ†æ
                    for dim in range(features_sample.shape[-1]):
                        dim_data = features_sample[:, dim]
                        dim_nan = np.isnan(dim_data).sum()
                        dim_inf = np.isinf(dim_data).sum()
                        if dim_nan > 0 or dim_inf > 0:
                            print(f"       ç»´åº¦{dim}: NaN={dim_nan}, Inf={dim_inf}")
                else:
                    print(f"     âœ… Featuresæ­£å¸¸")
                    
                if has_nan_labels or has_inf_labels:
                    print(f"     âŒ Labelsæœ‰å¼‚å¸¸å€¼: NaN={has_nan_labels}, Inf={has_inf_labels}")
                else:
                    print(f"     âœ… Labelsæ­£å¸¸")
                    
                # æ£€æŸ¥æ•°æ®èŒƒå›´
                print(f"     FeaturesèŒƒå›´: min={np.min(features_sample):.6f}, max={np.max(features_sample):.6f}")
                print(f"     LabelsèŒƒå›´: min={np.min(labels_sample):.6f}, max={np.max(labels_sample):.6f}")
                
        except Exception as e:
            print(f"     âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    return True

def test_model_numerical_stability():
    """æµ‹è¯•æ¨¡å‹åœ¨æœåŠ¡å™¨ç¯å¢ƒä¸‹çš„æ•°å€¼ç¨³å®šæ€§"""
    print("\nğŸ” æ¨¡å‹æ•°å€¼ç¨³å®šæ€§æµ‹è¯•:")
    
    with open('configs/config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"   ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    model = EventDenoisingMamba(config).to(device)
    model.eval()
    
    criterion = nn.BCEWithLogitsLoss()
    
    # æµ‹è¯•å„ç§æ•°æ®èŒƒå›´
    test_cases = [
        ("æ­£å¸¸æ•°æ®", {
            'features': torch.randn(1, 100, 4) * 0.1,
            'labels': torch.randint(0, 2, (100,), dtype=torch.float)
        }),
        ("å¤§æ•°å€¼", {
            'features': torch.randn(1, 100, 4) * 100,
            'labels': torch.randint(0, 2, (100,), dtype=torch.float)
        }),
        ("å°æ•°å€¼", {
            'features': torch.randn(1, 100, 4) * 1e-6,
            'labels': torch.randint(0, 2, (100,), dtype=torch.float)
        }),
        ("æå€¼æµ‹è¯•", {
            'features': torch.tensor([[[1000.0, 1000.0, 1000.0, 1.0]]] * 100),
            'labels': torch.ones(100, dtype=torch.float)
        })
    ]
    
    for case_name, data in test_cases:
        print(f"\n   æµ‹è¯•ç”¨ä¾‹: {case_name}")
        
        features = data['features'].to(device)
        labels = data['labels'].to(device)
        
        try:
            with torch.no_grad():
                model.reset_hidden_state()
                predictions = model(features)
                loss = criterion(predictions.squeeze(), labels)
                
                # æ£€æŸ¥ç»“æœ
                pred_has_nan = torch.isnan(predictions).any()
                pred_has_inf = torch.isinf(predictions).any()
                loss_has_nan = torch.isnan(loss)
                loss_has_inf = torch.isinf(loss)
                
                if pred_has_nan or pred_has_inf or loss_has_nan or loss_has_inf:
                    print(f"     âŒ å¼‚å¸¸å€¼æ£€æµ‹:")
                    print(f"       Predictions NaN: {pred_has_nan}, Inf: {pred_has_inf}")
                    print(f"       Loss NaN: {loss_has_nan}, Inf: {loss_has_inf}")
                    print(f"       Losså€¼: {loss.item() if not loss_has_nan else 'NaN'}")
                else:
                    print(f"     âœ… æ­£å¸¸, Loss: {loss.item():.6f}")
                    
        except Exception as e:
            print(f"     âŒ æµ‹è¯•å¤±è´¥: {e}")

def test_server_validation_pipeline():
    """æµ‹è¯•æœåŠ¡å™¨ä¸Šçš„å®Œæ•´éªŒè¯ç®¡çº¿"""
    print("\nğŸ” æœåŠ¡å™¨éªŒè¯ç®¡çº¿æµ‹è¯•:")
    
    with open('configs/config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    try:
        # åˆ›å»ºæ¨¡å‹å’Œæ•°æ®åŠ è½½å™¨
        model = EventDenoisingMamba(config).to(device)
        model.eval()
        
        train_loader, val_loader = create_unified_dataloaders(config)
        criterion = nn.BCEWithLogitsLoss()
        chunk_size = config['training']['chunk_size']
        
        print(f"   éªŒè¯åºåˆ—æ•°: {len(val_loader)}")
        print(f"   Chunkå¤§å°: {chunk_size}")
        
        total_loss = 0
        total_chunks_processed = 0
        
        with torch.no_grad():
            for seq_idx, (long_features, long_labels) in enumerate(val_loader):
                print(f"\n   å¤„ç†åºåˆ— {seq_idx + 1}/{len(val_loader)}")
                
                # é‡ç½®çŠ¶æ€
                model.reset_hidden_state()
                
                # æ•°æ®ç§»åŠ¨å’Œå½¢çŠ¶æ£€æŸ¥
                long_features = long_features.squeeze(0).to(device)
                long_labels = long_labels.squeeze(0).to(device)
                
                print(f"     åºåˆ—å½¢çŠ¶: features {long_features.shape}, labels {long_labels.shape}")
                
                # æ£€æŸ¥è¾“å…¥æ•°æ®å¼‚å¸¸å€¼
                input_nan = torch.isnan(long_features).any() or torch.isnan(long_labels).any()
                input_inf = torch.isinf(long_features).any() or torch.isinf(long_labels).any()
                
                if input_nan or input_inf:
                    print(f"     âŒ è¾“å…¥æ•°æ®å¼‚å¸¸: NaN={input_nan}, Inf={input_inf}")
                    continue
                
                # åˆ†å—å¤„ç†
                chunk_count = 0
                for i in range(0, long_features.shape[0], chunk_size):
                    chunk_features = long_features[i : i + chunk_size]
                    chunk_labels = long_labels[i : i + chunk_size]
                    
                    if chunk_features.shape[0] < 1:
                        continue
                    
                    chunk_count += 1
                    chunk_features = chunk_features.unsqueeze(0)
                    
                    # å‰å‘ä¼ æ’­
                    predictions = model(chunk_features)
                    
                    # æ£€æŸ¥é¢„æµ‹ç»“æœ
                    pred_nan = torch.isnan(predictions).any()
                    pred_inf = torch.isinf(predictions).any()
                    
                    if pred_nan or pred_inf:
                        print(f"     âŒ Chunk {chunk_count} é¢„æµ‹å¼‚å¸¸: NaN={pred_nan}, Inf={pred_inf}")
                        continue
                    
                    # è®¡ç®—æŸå¤±
                    loss = criterion(predictions.squeeze(), chunk_labels.float())
                    
                    # æ£€æŸ¥æŸå¤±
                    loss_nan = torch.isnan(loss)
                    loss_inf = torch.isinf(loss)
                    
                    if loss_nan or loss_inf:
                        print(f"     âŒ Chunk {chunk_count} æŸå¤±å¼‚å¸¸: NaN={loss_nan}, Inf={loss_inf}")
                        print(f"       PredictionsèŒƒå›´: [{predictions.min():.6f}, {predictions.max():.6f}]")
                        print(f"       LabelsèŒƒå›´: [{chunk_labels.min():.6f}, {chunk_labels.max():.6f}]")
                        continue
                    
                    # ç´¯è®¡ - ä½¿ç”¨æ­£ç¡®çš„æƒé‡
                    sequence_length = chunk_features.shape[1]  # æ­£ç¡®çš„æƒé‡
                    total_loss += loss.item() * sequence_length
                    total_chunks_processed += sequence_length
                    
                    if chunk_count <= 3:  # åªæ‰“å°å‰å‡ ä¸ªchunkçš„è¯¦ç»†ä¿¡æ¯
                        print(f"     Chunk {chunk_count}: Loss={loss.item():.6f}, æƒé‡={sequence_length}")
                
                print(f"     åºåˆ—å¤„ç†å®Œæˆï¼Œå…± {chunk_count} ä¸ªchunks")
                
                # é™åˆ¶åªå¤„ç†å‰å‡ ä¸ªåºåˆ—è¿›è¡Œè°ƒè¯•
                if seq_idx >= 2:
                    break
        
        # è®¡ç®—æœ€ç»ˆç»“æœ
        if total_chunks_processed > 0:
            avg_loss = total_loss / total_chunks_processed
            print(f"\nğŸ¯ éªŒè¯ç»“æœ:")
            print(f"   æ€»äº‹ä»¶æ•°: {total_chunks_processed}")
            print(f"   å¹³å‡æŸå¤±: {avg_loss:.6f}")
            
            # æœ€ç»ˆæ£€æŸ¥
            if np.isnan(avg_loss) or np.isinf(avg_loss):
                print(f"   âŒ æœ€ç»ˆç»“æœå¼‚å¸¸: {avg_loss}")
                return False
            else:
                print(f"   âœ… æœ€ç»ˆç»“æœæ­£å¸¸")
                return True
        else:
            print(f"   âŒ æ²¡æœ‰å¤„ç†ä»»ä½•äº‹ä»¶")
            return False
            
    except Exception as e:
        print(f"   âŒ éªŒè¯ç®¡çº¿å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»è°ƒè¯•å‡½æ•°"""
    print("ğŸš€ æœåŠ¡å™¨ç¯å¢ƒéªŒè¯NaNè°ƒè¯•")
    print("=" * 60)
    
    # è¿è¡Œå„é¡¹æ£€æŸ¥
    tests = [
        ("ç¯å¢ƒæ£€æŸ¥", check_environment),
        ("H5æ•°æ®å®Œæ•´æ€§", check_h5_data_integrity),
        ("æ¨¡å‹æ•°å€¼ç¨³å®šæ€§", test_model_numerical_stability),
        ("éªŒè¯ç®¡çº¿æµ‹è¯•", test_server_validation_pipeline)
    ]
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            if test_func is check_environment:
                test_func()  # ç¯å¢ƒæ£€æŸ¥æ²¡æœ‰è¿”å›å€¼
            else:
                result = test_func()
                if result is False:
                    print(f"âŒ {test_name} å‘ç°é—®é¢˜")
                else:
                    print(f"âœ… {test_name} æ­£å¸¸")
        except Exception as e:
            print(f"âŒ {test_name} å¤±è´¥: {e}")

if __name__ == "__main__":
    main()