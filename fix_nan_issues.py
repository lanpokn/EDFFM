#!/usr/bin/env python3
"""
ä¿®å¤NaNé—®é¢˜çš„è„šæœ¬
"""

import torch
import torch.nn as nn
import numpy as np
import yaml
import sys
sys.path.append('src')

from src.model import EventDenoisingMamba

def add_gradient_clipping_to_trainer():
    """åœ¨trainer.pyä¸­æ·»åŠ æ¢¯åº¦è£å‰ª"""
    
    trainer_code = '''
# åœ¨trainer.pyçš„train_one_epochå‡½æ•°ä¸­ï¼Œloss.backward()ä¹‹åæ·»åŠ ï¼š

# åŸä»£ç ï¼š
# loss.backward()
# self.optimizer.step()

# ä¿®æ”¹ä¸ºï¼š
loss.backward()

# æ·»åŠ æ¢¯åº¦è£å‰ªé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)

self.optimizer.step()
'''
    print("éœ€è¦åœ¨trainer.pyä¸­æ·»åŠ æ¢¯åº¦è£å‰ªï¼š")
    print(trainer_code)

def create_stable_model_patch():
    """åˆ›å»ºæ•°å€¼ç¨³å®šçš„æ¨¡å‹è¡¥ä¸"""
    
    print("\nåˆ›å»ºmodel.pyçš„æ•°å€¼ç¨³å®šè¡¥ä¸...")
    
    model_patch = '''
# åœ¨model.pyçš„forwardå‡½æ•°ä¸­æ·»åŠ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥ï¼š

def forward(self, features):
    batch_size, sequence_length, feature_dim = features.shape
    
    # éªŒè¯è¾“å…¥ç‰¹å¾ç»´åº¦ä¸º4ç»´
    expected_dim = self.config['model']['input_feature_dim']
    assert feature_dim == expected_dim, f"Expected {expected_dim}D features, got {feature_dim}D"
    
    # ğŸ”§ æ·»åŠ è¾“å…¥æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
    if torch.isnan(features).any() or torch.isinf(features).any():
        print(f"Warning: Input features contain NaN or Inf")
        # æ›¿æ¢NaNå’ŒInfä¸ºæœ‰é™å€¼
        features = torch.where(torch.isnan(features), torch.zeros_like(features), features)
        features = torch.where(torch.isinf(features), torch.sign(features) * 10.0, features)
    
    # ğŸ”§ é™åˆ¶è¾“å…¥èŒƒå›´é˜²æ­¢æ•°å€¼çˆ†ç‚¸
    features = torch.clamp(features, min=-10.0, max=10.0)
    
    # ç›´æ¥è¿›è¡ŒMambaå¤„ç†ï¼Œæ— éœ€ç‰¹å¾æå–
    x = self.embedding(features)
    for layer in self.layers:
        x = layer(x)
        
        # ğŸ”§ åœ¨æ¯å±‚ä¹‹åæ£€æŸ¥æ•°å€¼ç¨³å®šæ€§
        if torch.isnan(x).any() or torch.isinf(x).any():
            print(f"Warning: Layer output contains NaN or Inf")
            x = torch.where(torch.isnan(x), torch.zeros_like(x), x)
            x = torch.where(torch.isinf(x), torch.sign(x) * 10.0, x)
    
    logits = self.classification_head(x)
    
    # ğŸ”§ æœ€ç»ˆè¾“å‡ºæ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
    if torch.isnan(logits).any() or torch.isinf(logits).any():
        print(f"Warning: Output logits contain NaN or Inf")
        logits = torch.where(torch.isnan(logits), torch.zeros_like(logits), logits)
        logits = torch.where(torch.isinf(logits), torch.sign(logits) * 10.0, logits)
    
    return logits
'''
    print(model_patch)

def create_safe_loss_function():
    """åˆ›å»ºå®‰å…¨çš„æŸå¤±å‡½æ•°"""
    
    safe_loss_code = '''
# åˆ›å»ºä¸€ä¸ªæ•°å€¼ç¨³å®šçš„æŸå¤±å‡½æ•°ç±»
class SafeBCEWithLogitsLoss(nn.Module):
    def __init__(self):
        super().__init__()
        self.bce = nn.BCEWithLogitsLoss()
    
    def forward(self, predictions, targets):
        # æ£€æŸ¥è¾“å…¥
        if torch.isnan(predictions).any() or torch.isinf(predictions).any():
            print("Warning: Predictions contain NaN or Inf in loss calculation")
            predictions = torch.where(torch.isnan(predictions), torch.zeros_like(predictions), predictions)
            predictions = torch.where(torch.isinf(predictions), torch.sign(predictions) * 10.0, predictions)
        
        if torch.isnan(targets).any() or torch.isinf(targets).any():
            print("Warning: Targets contain NaN or Inf in loss calculation")
            targets = torch.where(torch.isnan(targets), torch.zeros_like(targets), targets)
        
        # é™åˆ¶logitsèŒƒå›´é˜²æ­¢æ•°å€¼æº¢å‡º
        predictions = torch.clamp(predictions, min=-50.0, max=50.0)
        
        loss = self.bce(predictions, targets)
        
        # æ£€æŸ¥æŸå¤±ç»“æœ
        if torch.isnan(loss) or torch.isinf(loss):
            print("Warning: Loss is NaN or Inf, returning small positive value")
            return torch.tensor(0.693, device=loss.device, requires_grad=True)  # ln(2)
        
        return loss

# åœ¨trainer.pyä¸­æ›¿æ¢ï¼š
# self.criterion = nn.BCEWithLogitsLoss()
# æ”¹ä¸ºï¼š
# self.criterion = SafeBCEWithLogitsLoss()
'''
    print(safe_loss_code)

def fix_feature_extraction():
    """ä¿®å¤ç‰¹å¾æå–ä¸­çš„æ•°å€¼é—®é¢˜"""
    
    feature_fix_code = '''
# åœ¨feature_extractor.pyä¸­ä¿®å¤æ•°å€¼èŒƒå›´é—®é¢˜ï¼š

def process_sequence(self, raw_events):
    if len(raw_events) == 0:
        return np.empty((0, 4))
        
    num_events = raw_events.shape[0]
    feature_sequence = np.zeros((num_events, 4), dtype=np.float32)
    
    # Extract coordinates, timestamps, and polarities
    x = raw_events[:, 0].astype(np.float32)
    y = raw_events[:, 1].astype(np.float32)  
    t = raw_events[:, 2].astype(np.float64)
    p = raw_events[:, 3].astype(np.float32)
    
    # ğŸ”§ ä¿®å¤å½’ä¸€åŒ–ï¼Œç¡®ä¿èŒƒå›´åœ¨[0,1]
    x_norm = np.clip(x / max(self.w - 1, 1), 0.0, 1.0)
    y_norm = np.clip(y / max(self.h - 1, 1), 0.0, 1.0)
    
    # ğŸ”§ ä¿®å¤dtè®¡ç®—ï¼Œé˜²æ­¢æº¢å‡º
    dt = np.zeros_like(t, dtype=np.float32)
    if len(t) > 1:
        dt_raw = np.diff(t)
        dt[1:] = np.clip(dt_raw, 0.0, 1000.0).astype(np.float32)  # é™åˆ¶æœ€å¤§dt
    dt[0] = 0.0
    
    # ğŸ”§ ç¡®ä¿polarityåœ¨{-1, 1}èŒƒå›´å†…
    p = np.clip(p, -1.0, 1.0)
    
    # Assemble features
    feature_sequence[:, 0] = x_norm
    feature_sequence[:, 1] = y_norm  
    feature_sequence[:, 2] = dt
    feature_sequence[:, 3] = p
    
    # ğŸ”§ æœ€ç»ˆæ£€æŸ¥ï¼Œç§»é™¤ä»»ä½•å¼‚å¸¸å€¼
    feature_sequence = np.where(np.isnan(feature_sequence), 0.0, feature_sequence)
    feature_sequence = np.where(np.isinf(feature_sequence), 0.0, feature_sequence)
    
    return feature_sequence
'''
    print(feature_fix_code)

def main():
    print("ğŸ”§ NaNé—®é¢˜ä¿®å¤æ–¹æ¡ˆ")
    print("=" * 50)
    
    print("\n1. æ¢¯åº¦è£å‰ªä¿®å¤ï¼š")
    add_gradient_clipping_to_trainer()
    
    print("\n2. æ¨¡å‹æ•°å€¼ç¨³å®šæ€§ä¿®å¤ï¼š")
    create_stable_model_patch()
    
    print("\n3. å®‰å…¨æŸå¤±å‡½æ•°ï¼š")
    create_safe_loss_function()
    
    print("\n4. ç‰¹å¾æå–ä¿®å¤ï¼š")
    fix_feature_extraction()
    
    print("\nğŸ¯ ç«‹å³å¯ç”¨çš„ä¿®å¤ï¼š")
    print("1. é‡æ–°è¿è¡Œç‰¹å¾ç”Ÿæˆä»¥ä¿®å¤æ•°æ®èŒƒå›´é—®é¢˜")
    print("2. åœ¨config.yamlä¸­å‡å°chunk_sizeä»32768åˆ°8192")
    print("3. æ·»åŠ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥åˆ°æ¨¡å‹forwardå‡½æ•°")

if __name__ == "__main__":
    main()