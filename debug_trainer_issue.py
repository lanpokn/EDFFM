#!/usr/bin/env python3
"""
ä¸“é—¨è°ƒè¯•trainerä¸­validation lossè®¡ç®—é—®é¢˜
"""

import yaml
import torch
import torch.nn as nn
import sys
sys.path.append('src')

from src.unified_dataset import create_unified_dataloaders
from src.model import EventDenoisingMamba

def debug_trainer_validation():
    """è°ƒè¯•trainer validationä¸­çš„å…·ä½“é—®é¢˜"""
    
    # åŠ è½½é…ç½®
    with open('configs/config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # åˆ›å»ºæ¨¡å‹å’Œæ•°æ®
    model = EventDenoisingMamba(config).to(device)
    model.eval()
    
    train_loader, val_loader = create_unified_dataloaders(config)
    criterion = nn.BCEWithLogitsLoss()
    chunk_size = config['training']['chunk_size']
    
    print(f"ğŸ” è°ƒè¯•trainer validationé—®é¢˜")
    print(f"   Chunk size: {chunk_size}")
    print(f"   Validation sequences: {len(val_loader)}")
    
    total_loss = 0
    total_chunks_processed = 0
    
    with torch.no_grad():
        for seq_idx, (long_features, long_labels) in enumerate(val_loader):
            if seq_idx >= 1:  # åªå¤„ç†ç¬¬ä¸€ä¸ªåºåˆ—
                break
                
            print(f"\n--- åˆ†æåºåˆ— {seq_idx + 1} ---")
            
            # é‡ç½®éšè—çŠ¶æ€
            model.reset_hidden_state()
            
            # è§£åŒ…
            long_features = long_features.squeeze(0).to(device)
            long_labels = long_labels.squeeze(0).to(device)
            
            print(f"   åŸå§‹åºåˆ—å½¢çŠ¶: features {long_features.shape}, labels {long_labels.shape}")
            
            # åˆ†å—å¤„ç†
            for i in range(0, min(chunk_size * 3, long_features.shape[0]), chunk_size):  # åªå¤„ç†å‰3å—
                chunk_features = long_features[i : i + chunk_size]
                chunk_labels = long_labels[i : i + chunk_size]
                
                if chunk_features.shape[0] < 1:
                    continue
                
                print(f"\n   Chunk {i//chunk_size + 1}:")
                print(f"     chunk_features before unsqueeze: {chunk_features.shape}")
                
                # æ·»åŠ æ‰¹æ¬¡ç»´åº¦ - è¿™æ˜¯å…³é”®ï¼
                chunk_features = chunk_features.unsqueeze(0)
                print(f"     chunk_features after unsqueeze: {chunk_features.shape}")
                print(f"     chunk_labels shape: {chunk_labels.shape}")
                
                # å‰å‘ä¼ æ’­
                predictions = model(chunk_features)
                print(f"     predictions shape: {predictions.shape}")
                
                # è®¡ç®—æŸå¤±
                loss = criterion(predictions.squeeze(), chunk_labels.float())
                print(f"     loss: {loss.item():.6f}")
                
                # è¿™é‡Œæ˜¯é—®é¢˜æ‰€åœ¨ï¼
                print(f"\n     ğŸš¨ è°ƒè¯•è®¡ç®—:")
                print(f"       len(chunk_features) = {len(chunk_features)} (batch size)")
                print(f"       chunk_features.shape[0] = {chunk_features.shape[0]} (batch size)")  
                print(f"       chunk_features.shape[1] = {chunk_features.shape[1]} (sequence length)")
                print(f"       chunk_labels.shape[0] = {chunk_labels.shape[0]} (sequence length)")
                
                # é”™è¯¯çš„è®¡ç®—æ–¹å¼ (å½“å‰trainerä¸­çš„æ–¹å¼)
                wrong_weight = len(chunk_features)  # è¿™æ˜¯batch_size=1
                wrong_contribution = loss.item() * wrong_weight
                
                # æ­£ç¡®çš„è®¡ç®—æ–¹å¼
                correct_weight = chunk_features.shape[1]  # è¿™æ˜¯sequence_length
                correct_contribution = loss.item() * correct_weight
                
                print(f"       âŒ é”™è¯¯æƒé‡: {wrong_weight} -> è´¡çŒ®: {wrong_contribution:.6f}")
                print(f"       âœ… æ­£ç¡®æƒé‡: {correct_weight} -> è´¡çŒ®: {correct_contribution:.6f}")
                
                # æŒ‰ç…§é”™è¯¯æ–¹å¼ç´¯è®¡ï¼ˆæ¨¡æ‹Ÿå½“å‰trainerï¼‰
                total_loss += loss.item() * len(chunk_features)
                total_chunks_processed += len(chunk_features)
                
                print(f"       ç´¯è®¡total_loss: {total_loss:.6f}")
                print(f"       ç´¯è®¡total_chunks_processed: {total_chunks_processed}")
    
    # æœ€ç»ˆè®¡ç®—
    if total_chunks_processed > 0:
        avg_loss = total_loss / total_chunks_processed
        print(f"\nğŸ¯ æœ€ç»ˆç»“æœ (é”™è¯¯çš„è®¡ç®—æ–¹å¼):")
        print(f"   total_loss: {total_loss:.6f}")
        print(f"   total_chunks_processed: {total_chunks_processed}")
        print(f"   avg_loss: {avg_loss:.6f}")
        
        if torch.isnan(torch.tensor(avg_loss)) or torch.isinf(torch.tensor(avg_loss)):
            print(f"   âŒ ç»“æœå¼‚å¸¸: {avg_loss}")
        else:
            print(f"   âœ… ç»“æœæ­£å¸¸: {avg_loss}")
    else:
        print(f"âŒ total_chunks_processed = 0ï¼Œä¼šå¯¼è‡´é™¤é›¶é”™è¯¯æˆ–è¿”å›0")

if __name__ == "__main__":
    debug_trainer_validation()