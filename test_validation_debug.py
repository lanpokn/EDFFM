#!/usr/bin/env python3
"""
ä¸“é—¨ç”¨äºè°ƒè¯•éªŒè¯ç®¡çº¿çš„æµ‹è¯•è„šæœ¬
æ£€æŸ¥æ•°æ®åŠ è½½ã€ç‰¹å¾æå–ã€æ¨¡å‹å‰å‘ä¼ æ’­ã€æŸå¤±è®¡ç®—çš„æ¯ä¸ªæ­¥éª¤
"""

import yaml
import torch
import torch.nn as nn
import numpy as np
import os
import sys
from torch.utils.data import DataLoader

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.append('src')

from src.unified_dataset import UnifiedSequenceDataset, create_unified_dataloaders
from src.model import EventDenoisingMamba

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open('configs/config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    return config

def check_tensor_for_nan_inf(tensor, name):
    """æ£€æŸ¥å¼ é‡ä¸­çš„NaNå’ŒInf"""
    has_nan = torch.isnan(tensor).any()
    has_inf = torch.isinf(tensor).any()
    
    if has_nan or has_inf:
        print(f"âŒ {name}: å‘ç°å¼‚å¸¸å€¼")
        if has_nan:
            nan_count = torch.isnan(tensor).sum().item()
            print(f"   NaNæ•°é‡: {nan_count}")
        if has_inf:
            inf_count = torch.isinf(tensor).sum().item()
            print(f"   Infæ•°é‡: {inf_count}")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        finite_mask = torch.isfinite(tensor)
        if finite_mask.any():
            finite_tensor = tensor[finite_mask]
            print(f"   æœ‰é™å€¼ç»Ÿè®¡: min={finite_tensor.min():.6f}, max={finite_tensor.max():.6f}, mean={finite_tensor.mean():.6f}")
        
        return True
    else:
        print(f"âœ… {name}: æ­£å¸¸ (min={tensor.min():.6f}, max={tensor.max():.6f}, mean={tensor.mean():.6f})")
        return False

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("\nğŸ” æµ‹è¯•æ•°æ®åŠ è½½...")
    
    config = load_config()
    
    # ç¡®ä¿ä½¿ç”¨loadæ¨¡å¼
    if config['data_pipeline']['mode'] != 'load':
        print("âŒ é…ç½®æ–‡ä»¶ä¸­data_pipeline.modeä¸æ˜¯'load'ï¼Œè¯·ç¡®ä¿å·²ç”ŸæˆéªŒè¯æ•°æ®")
        return False
    
    try:
        # åˆ›å»ºéªŒè¯æ•°æ®é›†
        val_dataset = UnifiedSequenceDataset(config, split='val')
        val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=0)
        
        print(f"âœ… éªŒè¯æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼ŒåŒ…å« {len(val_dataset)} ä¸ªåºåˆ—")
        
        # æµ‹è¯•åŠ è½½ç¬¬ä¸€ä¸ªæ ·æœ¬
        features, labels = next(iter(val_loader))
        print(f"âœ… æˆåŠŸåŠ è½½ç¬¬ä¸€ä¸ªæ ·æœ¬")
        print(f"   Features shape: {features.shape}")
        print(f"   Labels shape: {labels.shape}")
        
        # æ£€æŸ¥æ•°æ®å¼‚å¸¸å€¼
        features = features.squeeze(0)  # Remove batch dim
        labels = labels.squeeze(0)
        
        nan_found = False
        nan_found |= check_tensor_for_nan_inf(features, "Features")
        nan_found |= check_tensor_for_nan_inf(labels.float(), "Labels")
        
        # æ£€æŸ¥ç‰¹å¾çš„æ¯ä¸ªç»´åº¦
        print("\nğŸ“Š å„ç‰¹å¾ç»´åº¦è¯¦ç»†æ£€æŸ¥:")
        feature_names = ['x_norm', 'y_norm', 'dt', 'polarity']
        for i, name in enumerate(feature_names):
            if i < features.shape[-1]:
                feature_dim = features[:, i]
                nan_found |= check_tensor_for_nan_inf(feature_dim, f"Feature[{i}] {name}")
        
        return not nan_found
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_model_forward():
    """æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­"""
    print("\nğŸ” æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­...")
    
    config = load_config()
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    try:
        # åˆ›å»ºæ¨¡å‹
        model = EventDenoisingMamba(config).to(device)
        model.eval()
        
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 1
        seq_len = 100
        feature_dim = 4
        
        # åˆ›å»ºæ­£å¸¸èŒƒå›´çš„æµ‹è¯•ç‰¹å¾
        test_features = torch.randn(batch_size, seq_len, feature_dim).to(device)
        test_features[:, :, 0] = torch.rand(batch_size, seq_len).to(device)  # x_norm [0,1]
        test_features[:, :, 1] = torch.rand(batch_size, seq_len).to(device)  # y_norm [0,1]  
        test_features[:, :, 2] = torch.rand(batch_size, seq_len).to(device) * 1000  # dt [0,1000]
        test_features[:, :, 3] = torch.randint(-1, 2, (batch_size, seq_len), dtype=torch.float).to(device)  # polarity {-1,1}
        
        print("âœ… æµ‹è¯•ç‰¹å¾åˆ›å»ºæˆåŠŸ")
        check_tensor_for_nan_inf(test_features, "Test Features")
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            model.reset_hidden_state()
            predictions = model(test_features)
        
        print(f"âœ… æ¨¡å‹å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"   Predictions shape: {predictions.shape}")
        
        nan_found = check_tensor_for_nan_inf(predictions, "Model Predictions")
        
        return not nan_found
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_loss_calculation():
    """æµ‹è¯•æŸå¤±è®¡ç®—"""
    print("\nğŸ” æµ‹è¯•æŸå¤±è®¡ç®—...")
    
    try:
        criterion = nn.BCEWithLogitsLoss()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 100
        predictions = torch.randn(batch_size, 1)  # logits
        labels = torch.randint(0, 2, (batch_size,), dtype=torch.float)
        
        print("âœ… æµ‹è¯•æ•°æ®åˆ›å»ºæˆåŠŸ")
        check_tensor_for_nan_inf(predictions, "Test Predictions")
        check_tensor_for_nan_inf(labels, "Test Labels")
        
        # è®¡ç®—æŸå¤±
        loss = criterion(predictions.squeeze(), labels)
        
        print(f"âœ… æŸå¤±è®¡ç®—æˆåŠŸ")
        print(f"   Loss value: {loss.item():.6f}")
        
        nan_found = check_tensor_for_nan_inf(loss.unsqueeze(0), "Loss")
        
        # æµ‹è¯•è¾¹ç•Œæƒ…å†µ
        print("\nğŸ” æµ‹è¯•è¾¹ç•Œæƒ…å†µ...")
        
        # æå¤§logits
        extreme_predictions = torch.tensor([100.0, -100.0, 0.0]).unsqueeze(1)
        extreme_labels = torch.tensor([1.0, 0.0, 0.5])
        extreme_loss = criterion(extreme_predictions.squeeze(), extreme_labels)
        print(f"   æå€¼æµ‹è¯•æŸå¤±: {extreme_loss.item():.6f}")
        nan_found |= check_tensor_for_nan_inf(extreme_loss.unsqueeze(0), "Extreme Loss")
        
        return not nan_found
        
    except Exception as e:
        print(f"âŒ æŸå¤±è®¡ç®—å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_validation_pipeline():
    """æµ‹è¯•å®Œæ•´éªŒè¯ç®¡çº¿"""
    print("\nğŸ” æµ‹è¯•å®Œæ•´éªŒè¯ç®¡çº¿...")
    
    config = load_config()
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    try:
        # åˆ›å»ºæ¨¡å‹å’Œæ•°æ®
        model = EventDenoisingMamba(config).to(device)
        model.eval()
        
        val_dataset = UnifiedSequenceDataset(config, split='val')
        val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=0)
        
        criterion = nn.BCEWithLogitsLoss()
        chunk_size = config['training']['chunk_size']
        
        print(f"âœ… ç®¡çº¿ç»„ä»¶åˆ›å»ºæˆåŠŸ")
        print(f"   Chunk size: {chunk_size}")
        
        total_loss = 0
        total_chunks_processed = 0
        nan_found = False
        
        # åªå¤„ç†å‰3ä¸ªåºåˆ—è¿›è¡Œè°ƒè¯•
        max_sequences = min(3, len(val_loader))
        
        with torch.no_grad():
            for seq_idx, (long_features, long_labels) in enumerate(val_loader):
                if seq_idx >= max_sequences:
                    break
                    
                print(f"\n--- å¤„ç†åºåˆ— {seq_idx + 1}/{max_sequences} ---")
                
                # é‡ç½®éšè—çŠ¶æ€
                model.reset_hidden_state()
                
                # è§£åŒ…æ‰¹æ¬¡ç»´åº¦
                long_features = long_features.squeeze(0).to(device)
                long_labels = long_labels.squeeze(0).to(device)
                
                print(f"   åºåˆ—é•¿åº¦: {long_features.shape[0]}")
                
                # æ£€æŸ¥è¾“å…¥æ•°æ®
                seq_nan_found = False
                seq_nan_found |= check_tensor_for_nan_inf(long_features, f"Seq{seq_idx+1} Features")
                seq_nan_found |= check_tensor_for_nan_inf(long_labels.float(), f"Seq{seq_idx+1} Labels")
                
                if seq_nan_found:
                    nan_found = True
                    print(f"âŒ åºåˆ— {seq_idx + 1} è¾“å…¥æ•°æ®æœ‰å¼‚å¸¸å€¼ï¼Œè·³è¿‡")
                    continue
                
                # åˆ†å—å¤„ç†
                num_chunks = 0
                for i in range(0, long_features.shape[0], chunk_size):
                    chunk_features = long_features[i : i + chunk_size]
                    chunk_labels = long_labels[i : i + chunk_size]
                    
                    if chunk_features.shape[0] < 1:
                        continue
                    
                    num_chunks += 1
                    print(f"   Chunk {num_chunks}: {chunk_features.shape[0]} events")
                    
                    # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
                    chunk_features = chunk_features.unsqueeze(0)
                    
                    # å‰å‘ä¼ æ’­
                    predictions = model(chunk_features)
                    
                    # æ£€æŸ¥é¢„æµ‹ç»“æœ
                    chunk_nan_found = check_tensor_for_nan_inf(predictions, f"Seq{seq_idx+1} Chunk{num_chunks} Predictions")
                    
                    if chunk_nan_found:
                        nan_found = True
                        print(f"âŒ åºåˆ— {seq_idx + 1} Chunk {num_chunks} é¢„æµ‹ç»“æœæœ‰å¼‚å¸¸å€¼")
                        continue
                    
                    # è®¡ç®—æŸå¤±
                    loss = criterion(predictions.squeeze(), chunk_labels.float())
                    
                    print(f"     Loss: {loss.item():.6f}")
                    
                    # æ£€æŸ¥æŸå¤±
                    loss_nan_found = check_tensor_for_nan_inf(loss.unsqueeze(0), f"Seq{seq_idx+1} Chunk{num_chunks} Loss")
                    
                    if loss_nan_found:
                        nan_found = True
                        print(f"âŒ åºåˆ— {seq_idx + 1} Chunk {num_chunks} æŸå¤±è®¡ç®—æœ‰å¼‚å¸¸å€¼")
                        continue
                    
                    # ç´¯è®¡æŸå¤±
                    total_loss += loss.item() * len(chunk_features)
                    total_chunks_processed += len(chunk_features)
        
        # è®¡ç®—å¹³å‡æŸå¤±
        if total_chunks_processed > 0:
            avg_loss = total_loss / total_chunks_processed
            print(f"\nâœ… éªŒè¯ç®¡çº¿å®Œæˆ")
            print(f"   æ€»äº‹ä»¶æ•°: {total_chunks_processed}")
            print(f"   å¹³å‡æŸå¤±: {avg_loss:.6f}")
            
            if np.isnan(avg_loss) or np.isinf(avg_loss):
                print(f"âŒ æœ€ç»ˆå¹³å‡æŸå¤±å¼‚å¸¸: {avg_loss}")
                nan_found = True
        else:
            print(f"âŒ æ²¡æœ‰å¤„ç†ä»»ä½•äº‹ä»¶")
            nan_found = True
        
        return not nan_found
        
    except Exception as e:
        print(f"âŒ éªŒè¯ç®¡çº¿å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹éªŒè¯ç®¡çº¿NaNè°ƒè¯•æµ‹è¯•")
    print("=" * 60)
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    tests = [
        ("æ•°æ®åŠ è½½", test_data_loading),
        ("æ¨¡å‹å‰å‘ä¼ æ’­", test_model_forward), 
        ("æŸå¤±è®¡ç®—", test_loss_calculation),
        ("å®Œæ•´éªŒè¯ç®¡çº¿", test_validation_pipeline)
    ]
    
    results = {}
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥: {e}")
            results[test_name] = False
    
    # æ€»ç»“
    print(f"\n{'='*60}")
    print("ğŸ¯ æµ‹è¯•æ€»ç»“:")
    
    all_passed = True
    for test_name, passed in results.items():
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
        if not passed:
            all_passed = False
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼éªŒè¯ç®¡çº¿åº”è¯¥æ­£å¸¸å·¥ä½œã€‚")
    else:
        print("\nâš ï¸  å‘ç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°å¤±è´¥çš„æµ‹è¯•é¡¹ã€‚")

if __name__ == "__main__":
    main()